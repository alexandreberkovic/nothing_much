{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75366872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73649ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0625cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "#import sklearn.datasets\n",
    "\n",
    "import libs as lib\n",
    "import libs.plot\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pathlib import Path\n",
    "from platform import python_version\n",
    "\n",
    "import pdb\n",
    "import gpustat\n",
    "\n",
    "from models.acwgan_gp import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "from torch import optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import grad\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99e90f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.1\n",
      "Torchvision Version:  0.6.1\n",
      "Python Version:  3.6.13\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "print(\"Python Version: \",python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d78a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdffdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db1572e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory:  15.843721216\n",
      "Reserved memory:  0.0\n",
      "Allocated memory:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total memory: \", t/10**9)\n",
    "print(\"Reserved memory: \", r/10**9)\n",
    "print(\"Allocated memory: \", a/10**9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5dddf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/ec2-user/SageMaker/portrait_landscape/train'\n",
    "VAL_DIR = '/home/ec2-user/SageMaker/portrait_landscape/test'\n",
    "\n",
    "IMAGE_DATA_SET = 'raw' #change this to something else, e.g. 'imagenets' or 'raw' if your data is just a folder of raw images. \n",
    "#If you use lmdb, you'll need to write the loader by yourself, see load_data\n",
    "TRAINING_CLASS = os.listdir(DATA_DIR)\n",
    "VAL_CLASS = os.listdir(VAL_DIR)\n",
    "NUM_CLASSES = len(TRAINING_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e8d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(DATA_DIR) == 0:\n",
    "    raise Exception('Please specify path to data directory!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "964db254",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESTORE_MODE = False  # if True, it will load saved model from OUT_PATH and continue to train\n",
    "START_ITER = 0 # starting iteration \n",
    "OUTPUT_PATH = 'output/' # output path where result (.e.g drawing images, cost, chart) will be stored\n",
    "# MODE = 'wgan-gp'\n",
    "DIM = 128 # Model dimensionality\n",
    "CRITIC_ITERS = 50 # How many iterations to train the critic for\n",
    "GENER_ITERS = 1\n",
    "N_GPUS = 1 # Number of GPUs\n",
    "BATCH_SIZE = 64# Batch size. Must be a multiple of N_GPUS\n",
    "END_ITER = 100000 # How many iterations to train for\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = DIM*DIM*3 # Number of pixels in each iamge\n",
    "ACGAN_SCALE = 1. # How to scale the critic's ACGAN loss relative to WGAN loss\n",
    "ACGAN_SCALE_G = 1. # How to scale generator's ACGAN loss relative to WGAN loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4394e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMemoryUsage(device=1):\n",
    "    gpu_stats = gpustat.GPUStatCollection.new_query()\n",
    "    item = gpu_stats.jsonify()[\"gpus\"][device]\n",
    "    print('Used/total: ' + \"{}/{}\".format(item[\"memory.used\"], item[\"memory.total\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89f6901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, MyConvo2d): \n",
    "        if m.conv.weight is not None:\n",
    "            if m.he_init:\n",
    "                init.kaiming_uniform_(m.conv.weight)\n",
    "            else:\n",
    "                init.xavier_uniform_(m.conv.weight)\n",
    "        if m.conv.bias is not None:\n",
    "            init.constant_(m.conv.bias, 0.0)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        if m.weight is not None:\n",
    "            init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f1b7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_folder, classes):\n",
    "    data_transform = transforms.Compose([\n",
    "                 transforms.Scale(DIM),\n",
    "                 transforms.CenterCrop(DIM),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])\n",
    "                ])\n",
    "    if IMAGE_DATA_SET == 'lsun':\n",
    "        dataset =  datasets.LSUN(path_to_folder, classes=classes, transform=data_transform)\n",
    "    else:\n",
    "        dataset = datasets.ImageFolder(root=path_to_folder,transform=data_transform)\n",
    "    dataset_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=5, drop_last=True, pin_memory=True)\n",
    "    return dataset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6077a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(BATCH_SIZE, 1)\n",
    "    alpha = alpha.expand(BATCH_SIZE, int(real_data.nelement()/BATCH_SIZE)).contiguous()\n",
    "    alpha = alpha.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "    alpha = alpha.to(device)\n",
    "\n",
    "    fake_data = fake_data.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)   \n",
    "\n",
    "    disc_interpolates, _ = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7e19142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(netG, noise=None):\n",
    "    if noise is None:\n",
    "        rand_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
    "        noise = gen_rand_noise_with_label(rand_label)\n",
    "    with torch.no_grad():\n",
    "        noisev = noise\n",
    "    samples = netG(noisev)\n",
    "    samples = samples.view(BATCH_SIZE, 3, DIM, DIM)\n",
    "\n",
    "    samples = samples * 0.5 + 0.5\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8877a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rand_noise_with_label(label=None):\n",
    "    if label is None:\n",
    "        label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
    "    #attach label into noise\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, 128))\n",
    "    prefix = np.zeros((BATCH_SIZE, NUM_CLASSES))\n",
    "    prefix[np.arange(BATCH_SIZE), label] = 1\n",
    "    noise[np.arange(BATCH_SIZE), :NUM_CLASSES] = prefix[np.arange(BATCH_SIZE)]\n",
    "\n",
    "    noise = torch.from_numpy(noise).float()\n",
    "    noise = noise.to(device)\n",
    "\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "441562fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "fixed_label = []\n",
    "for c in range(BATCH_SIZE):\n",
    "    fixed_label.append(c%NUM_CLASSES)\n",
    "fixed_noise = gen_rand_noise_with_label(fixed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c6936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESTORE_MODE:\n",
    "    aG = torch.load(OUTPUT_PATH + \"generator.pt\")\n",
    "    aD = torch.load(OUTPUT_PATH + \"discriminator.pt\")\n",
    "else:\n",
    "    aG = GoodGenerator(DIM,DIM*DIM*3)\n",
    "    aD = GoodDiscriminator(DIM, NUM_CLASSES)\n",
    "    \n",
    "    aG.apply(weights_init)\n",
    "    aD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41e1672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "optimizer_g = torch.optim.Adam(aG.parameters(), lr=LR, betas=(0,0.9))\n",
    "optimizer_d = torch.optim.Adam(aD.parameters(), lr=LR, betas=(0,0.9))\n",
    "\n",
    "aux_criterion = nn.CrossEntropyLoss() # nn.NLLLoss()\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "aG = aG.to(device)\n",
    "aD = aD.to(device)\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed153f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad1acb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://github.com/caogang/wgan-gp/blob/master/gan_cifar10.py\n",
    "def train():\n",
    "    #writer = SummaryWriter()\n",
    "    dataloader = load_data(DATA_DIR, TRAINING_CLASS)\n",
    "    dataiter = iter(dataloader)\n",
    "    for iteration in range(START_ITER, END_ITER):\n",
    "        start_time = time.time()\n",
    "        print(\"Iter: \" + str(iteration))\n",
    "        start = timer()\n",
    "        #---------------------TRAIN G------------------------\n",
    "        for p in aD.parameters():\n",
    "            p.requires_grad_(False)  # freeze D\n",
    "\n",
    "        gen_cost = None\n",
    "        for i in range(GENER_ITERS):\n",
    "            print(\"Generator iters: \" + str(i))\n",
    "            aG.zero_grad()\n",
    "            f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
    "            noise = gen_rand_noise_with_label(f_label)\n",
    "            noise.requires_grad_(True)\n",
    "            fake_data = aG(noise)\n",
    "            gen_cost, gen_aux_output = aD(fake_data)\n",
    "\n",
    "            aux_label = torch.from_numpy(f_label).long()\n",
    "            aux_label = aux_label.to(device)\n",
    "            aux_errG = aux_criterion(gen_aux_output, aux_label).mean()\n",
    "            gen_cost = -gen_cost.mean()\n",
    "            g_cost = ACGAN_SCALE_G*aux_errG + gen_cost\n",
    "            g_cost.backward()\n",
    "        \n",
    "        optimizer_g.step()\n",
    "        end = timer()\n",
    "        print(f'---train G elapsed time: {end - start}')\n",
    "        #---------------------TRAIN D------------------------\n",
    "        for p in aD.parameters():  # reset requires_grad\n",
    "            p.requires_grad_(True)  # they are set to False below in training G\n",
    "        for i in range(CRITIC_ITERS):\n",
    "            print(\"Critic iter: \" + str(i))\n",
    "            \n",
    "            start = timer()\n",
    "            aD.zero_grad()\n",
    "\n",
    "            # gen fake data and load real data\n",
    "            f_label = np.random.randint(0, NUM_CLASSES, BATCH_SIZE)\n",
    "            noise = gen_rand_noise_with_label(f_label)\n",
    "            with torch.no_grad():\n",
    "                noisev = noise  # totally freeze G, training D\n",
    "            fake_data = aG(noisev).detach()\n",
    "            end = timer(); print(f'---gen G elapsed time: {end-start}')\n",
    "            start = timer()\n",
    "            batch = next(dataiter, None)\n",
    "            if batch is None:\n",
    "                dataiter = iter(dataloader)\n",
    "                batch = dataiter.next()\n",
    "            real_data = batch[0] #batch[1] contains labels\n",
    "            real_data.requires_grad_(True)\n",
    "            real_label = batch[1]\n",
    "            #print(\"r_label\" + str(r_label))\n",
    "            end = timer(); print(f'---load real imgs elapsed time: {end-start}')\n",
    "\n",
    "            start = timer()\n",
    "            real_data = real_data.to(device)\n",
    "            real_label = real_label.to(device)\n",
    "\n",
    "            # train with real data\n",
    "            disc_real, aux_output = aD(real_data)\n",
    "            aux_errD_real = aux_criterion(aux_output, real_label)\n",
    "            errD_real = aux_errD_real.mean()\n",
    "            disc_real = disc_real.mean()\n",
    "\n",
    "\n",
    "            # train with fake data\n",
    "            disc_fake, aux_output = aD(fake_data)\n",
    "            #aux_errD_fake = aux_criterion(aux_output, fake_label)\n",
    "            #errD_fake = aux_errD_fake.mean()\n",
    "            disc_fake = disc_fake.mean()\n",
    "\n",
    "            #showMemoryUsage(0)\n",
    "            # train with interpolates data\n",
    "            gradient_penalty = calc_gradient_penalty(aD, real_data, fake_data)\n",
    "            #showMemoryUsage(0)\n",
    "\n",
    "            # final disc cost\n",
    "            disc_cost = disc_fake - disc_real + gradient_penalty\n",
    "            disc_acgan = errD_real #+ errD_fake\n",
    "            (disc_cost + ACGAN_SCALE*disc_acgan).backward()\n",
    "            w_dist = disc_fake  - disc_real\n",
    "            optimizer_d.step()\n",
    "            #------------------VISUALIZATION----------\n",
    "            if i == CRITIC_ITERS-1:\n",
    "                writer.add_scalar('data/disc_cost', disc_cost, iteration)\n",
    "                #writer.add_scalar('data/disc_fake', disc_fake, iteration)\n",
    "                #writer.add_scalar('data/disc_real', disc_real, iteration)\n",
    "                writer.add_scalar('data/gradient_pen', gradient_penalty, iteration)\n",
    "                writer.add_scalar('data/ac_disc_cost', disc_acgan, iteration)\n",
    "                writer.add_scalar('data/ac_gen_cost', aux_errG, iteration)\n",
    "                #writer.add_scalar('data/d_conv_weight_mean', [i for i in aD.children()][0].conv.weight.data.clone().mean(), iteration)\n",
    "                #writer.add_scalar('data/d_linear_weight_mean', [i for i in aD.children()][-1].weight.data.clone().mean(), iteration)\n",
    "                #writer.add_scalar('data/fake_data_mean', fake_data.mean())\n",
    "                #writer.add_scalar('data/real_data_mean', real_data.mean())\n",
    "                #if iteration %200==99:\n",
    "                #    paramsD = aD.named_parameters()\n",
    "                #    for name, pD in paramsD:\n",
    "                #        writer.add_histogram(\"D.\" + name, pD.clone().data.cpu().numpy(), iteration)\n",
    "                if iteration %200==199:\n",
    "                    body_model = [i for i in aD.children()][0]\n",
    "                    layer1 = body_model.conv\n",
    "                    xyz = layer1.weight.data.clone()\n",
    "                    tensor = xyz.cpu()\n",
    "                    tensors = torchvision.utils.make_grid(tensor, nrow=8,padding=1)\n",
    "                    writer.add_image('D/conv1', tensors, iteration)\n",
    "\n",
    "            end = timer(); print(f'---train D elapsed time: {end-start}')\n",
    "        #---------------VISUALIZATION---------------------\n",
    "        writer.add_scalar('data/gen_cost', gen_cost, iteration)\n",
    "        #if iteration %200==199:\n",
    "        #   paramsG = aG.named_parameters()\n",
    "        #   for name, pG in paramsG:\n",
    "        #       writer.add_histogram('G.' + name, pG.clone().data.cpu().numpy(), iteration)\n",
    "\t#----------------------Generate images-----------------\n",
    "\n",
    "        lib.plot.plot(OUTPUT_PATH + 'time', time.time() - start_time)\n",
    "        lib.plot.plot(OUTPUT_PATH + 'train_disc_cost', disc_cost.cpu().data.numpy())\n",
    "        lib.plot.plot(OUTPUT_PATH + 'train_gen_cost', gen_cost.cpu().data.numpy())\n",
    "        lib.plot.plot(OUTPUT_PATH + 'wasserstein_distance', w_dist.cpu().data.numpy())\n",
    "        if iteration % 200==199:\n",
    "            val_loader = load_data(VAL_DIR, VAL_CLASS)\n",
    "            dev_disc_costs = []\n",
    "            for _, images in enumerate(val_loader):\n",
    "                imgs = torch.Tensor(images[0])\n",
    "               \timgs = imgs.to(device)\n",
    "                with torch.no_grad():\n",
    "            \t    imgs_v = imgs\n",
    "\n",
    "                D, _ = aD(imgs_v)\n",
    "                _dev_disc_cost = -D.mean().cpu().data.numpy()\n",
    "                dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot(OUTPUT_PATH + 'dev_disc_cost.png', np.mean(dev_disc_costs))\n",
    "            lib.plot.flush()\t\n",
    "            gen_images = generate_image(aG, fixed_noise)\n",
    "            torchvision.utils.save_image(gen_images, OUTPUT_PATH + 'samples_{}.png'.format(iteration), nrow=8, padding=2)\n",
    "            grid_images = torchvision.utils.make_grid(gen_images, nrow=8, padding=2)\n",
    "            writer.add_image('images', grid_images, iteration)\n",
    "            #gen_images = generate_image(iteration, aG, persistant_noise)\n",
    "            #gen_images = torchvision.utils.make_grid(torch.from_numpy(gen_images), nrow=8, padding=1)\n",
    "            #writer.add_image('images', gen_images, iteration)\n",
    "\t#----------------------Save model----------------------\n",
    "            torch.save(aG, OUTPUT_PATH + \"generator.pt\")\n",
    "            torch.save(aD, OUTPUT_PATH + \"discriminator.pt\")\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd8cf257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "Generator iters: 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.76 GiB total capacity; 13.94 GiB already allocated; 11.75 MiB free; 13.96 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-e17409394ea6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_rand_noise_with_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mgen_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_aux_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Masters-thesis/AC-WGAN torch/models/acwgan_gp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrb1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrb2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrb3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Masters-thesis/AC-WGAN torch/models/acwgan_gp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Masters-thesis/AC-WGAN torch/models/acwgan_gp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth_to_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Masters-thesis/AC-WGAN torch/models/acwgan_gp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mspl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mstacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_depth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.76 GiB total capacity; 13.94 GiB already allocated; 11.75 MiB free; 13.96 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74637f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
