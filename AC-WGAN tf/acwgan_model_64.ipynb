{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36649901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6654f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d449cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f64d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimension of images you want to be passed in to the network\n",
    "DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070d28de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your own path to images\n",
    "# src_img_path  = Path('/home/ec2-user/SageMaker/genre-128')\n",
    "src_img_path  = Path('/home/ec2-user/SageMaker/portrait_landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267846d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(src_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938ca201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14981"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(src_img_path,'0')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc18ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary should be updated to hold the absolute number of images associated with each genre used during training\n",
    "styles = {\n",
    "    \"portraits\": 14980,\n",
    "    \"landscapes\": 14971\n",
    "}\n",
    "\n",
    "styleNum = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 1\n",
    "}\n",
    "    \n",
    "curPos = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "651cbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNums = {}\n",
    "trainNums = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4c0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set of images made up of 1/20 of the images (per genre)\n",
    "for k, v in styles.items():\n",
    "    # put a twentieth of paintings in here\n",
    "    nums = range(v)\n",
    "    random.shuffle(list(nums))\n",
    "    testNums[k] = nums[0 : v // 20]\n",
    "    trainNums[k] = nums[v // 20 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8021e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_gen(gen):\n",
    "    while True:\n",
    "        for (images, labels) in gen():\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988db2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(files, batch_size, n_classes): # add genre parameter\n",
    "    if batch_size % n_classes != 0:\n",
    "        raise ValueError(\n",
    "            \"Batch size {} must be divisible by num classes {}\".format(batch_size, n_classes)\n",
    "        )\n",
    "\n",
    "    class_batch = batch_size // n_classes\n",
    "\n",
    "    generators = []\n",
    "\n",
    "    def get_epoch():\n",
    "\n",
    "        while True:\n",
    "\n",
    "            images = np.zeros((batch_size, 3, DIM, DIM), dtype=\"int32\")\n",
    "            labels = np.zeros((batch_size, n_classes))\n",
    "            n = 0\n",
    "            for style in styles:\n",
    "#             for style in genre:\n",
    "                styleLabel = styleNum[style]\n",
    "                curr = curPos[style]\n",
    "                for _ in range(class_batch):\n",
    "                    if curr == styles[style]:\n",
    "                        curr = 0\n",
    "                        random.shuffle(list(files[style]))\n",
    "                    img_path = str(Path(src_img_path, str(styleLabel), str(curr) + \".png\"))\n",
    "                    image = Image.open(img_path).convert(mode=\"RGB\")\n",
    "                    image = np.asarray(image)\n",
    "\n",
    "                    images[n % batch_size] = image.transpose(2, 0, 1)\n",
    "                    labels[n % batch_size, int(styleLabel)] = 1\n",
    "                    n += 1\n",
    "                    curr += 1\n",
    "                curPos[style] = curr\n",
    "\n",
    "            # randomize things but keep relationship between a conditioning vector and its associated image\n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.shuffle(images)\n",
    "            np.random.set_state(rng_state)\n",
    "            np.random.shuffle(labels)\n",
    "            yield (images, labels)\n",
    "\n",
    "    return get_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75a6c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size):\n",
    "    return (\n",
    "        make_generator(trainNums, batch_size, len(styles)),\n",
    "        make_generator(testNums, batch_size, len(styles)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f09d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "# import tflib.wikiart_genre\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09cdd4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a3677ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fe1ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "426ae4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6448996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 84\n",
      "\tCLASSES: 2\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDIM: 64\n",
      "\tITERS: 200000\n",
      "\tLAMBDA: 10\n",
      "\tMODE: acwgan\n",
      "\tN_GPUS: 1\n",
      "\tOUTPUT_DIM: 12288\n",
      "\tPREITERATIONS: 2000\n"
     ]
    }
   ],
   "source": [
    "MODE = \"acwgan\"  # dcgan, wgan, wgan-gp, lsgan\n",
    "genre = ['portraits','landscapes']\n",
    "DIM = 64  # Model dimensionality\n",
    "CRITIC_ITERS = 5  # How many iterations to train the critic for, increase it to 50 later\n",
    "N_GPUS = 1  # Number of GPUs\n",
    "BATCH_SIZE = 84  # Batch size. Must be a multiple of CLASSES and N_GPUS\n",
    "ITERS = 200000  # How many iterations to train for\n",
    "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = DIM * DIM * 3  # Number of pixels in each image\n",
    "CLASSES = len(genre)  # Number of classes, for genres probably 14\n",
    "PREITERATIONS = 2000  # Number of preiteration training cycles to run\n",
    "lib.print_model_settings(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b975d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that directory exists where ground truth and plots will be saved to.\n",
    "Path('generated').mkdir(parents=True, exist_ok=True)\n",
    "Path('models').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9b0b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratorAndDiscriminator():\n",
    "    return kACGANGenerator, kACGANDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea63d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [\"/gpu:{}\".format(i) for i in range(N_GPUS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5540259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha * x, x)\n",
    "\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "\n",
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return LeakyReLU(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba1f9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batchnorm(name, axes, inputs):\n",
    "\n",
    "    if (\"Discriminator\" in name) and (MODE == \"wgan-gp\" or MODE == \"acwgan\"):\n",
    "        if axes != [0, 2, 3]:\n",
    "            raise Exception(\"Layernorm over non-standard axes is unsupported\")\n",
    "        return lib.ops.layernorm.Layernorm(name, [1, 2, 3], inputs)\n",
    "    else:\n",
    "        return lib.ops.batchnorm.Batchnorm(name, axes, inputs, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93c72441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixcnn_gated_nonlinearity(name, output_dim, a, b, c=None, d=None):\n",
    "    if c is not None and d is not None:\n",
    "        a = a + c\n",
    "        b = b + d\n",
    "\n",
    "    result = tf.sigmoid(a) * tf.tanh(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e11a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubpixelConv2D(*args, **kwargs):\n",
    "    kwargs[\"output_dim\"] = 4 * kwargs[\"output_dim\"]\n",
    "    output = lib.ops.conv2d.Conv2D(*args, **kwargs)\n",
    "    output = tf.transpose(output, [0, 2, 3, 1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0, 3, 1, 2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e73630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(\n",
    "    name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True\n",
    "):\n",
    "    \"\"\"\n",
    "    resample: None, 'down', or 'up'\n",
    "    \"\"\"\n",
    "    if resample == \"down\":\n",
    "        conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "            stride=2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == \"up\":\n",
    "        conv_shortcut = SubpixelConv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.deconv2d.Deconv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == None:\n",
    "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim // 2\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"invalid resample value\")\n",
    "\n",
    "    if output_dim == input_dim and resample == None:\n",
    "        shortcut = inputs  # Identity skip-connection\n",
    "    else:\n",
    "        shortcut = conv_shortcut(\n",
    "            name + \".Shortcut\",\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            filter_size=1,\n",
    "            he_init=False,\n",
    "            biases=True,\n",
    "            inputs=inputs,\n",
    "        )\n",
    "\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1(\n",
    "        name + \".Conv1\", filter_size=1, inputs=output, he_init=he_init, weightnorm=False\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1b(\n",
    "        name + \".Conv1B\",\n",
    "        filter_size=filter_size,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_2(\n",
    "        name + \".Conv2\",\n",
    "        filter_size=1,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "        biases=False,\n",
    "    )\n",
    "    output = Batchnorm(name + \".BN\", [0, 2, 3], output)\n",
    "\n",
    "    return shortcut + (0.3 * output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c050f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANGenerator(\n",
    "    n_samples,\n",
    "    numClasses,\n",
    "    labels,\n",
    "    noise=None,\n",
    "    dim=DIM,\n",
    "    bn=True,\n",
    "    nonlinearity=tf.nn.relu,\n",
    "    condition=None,\n",
    "):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    noise = tf.concat([noise, labels], 1)\n",
    "\n",
    "    output = lib.ops.linear.Linear(\n",
    "        \"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise\n",
    "    )  # probs need to recalculate dimensions\n",
    "    print('Generator output 1: ', output, output.shape)\n",
    "    output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "    print('Generator output 1 reshape: ', output, output.shape)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "        print('Generator output 1 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 8 * dim * 2, 4, 4])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl1\",\n",
    "        8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 1 final: ', output)\n",
    "    print('Structure 1: ', 8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "    print('Generator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "        print('Generator output 2 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl2\",\n",
    "        4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 2 final: ', output)\n",
    "    print('Structure 2: ', 4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "    print('Generator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "        print('Generator output 3 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim * 2, 16, 16])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl3\",\n",
    "        2 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 3 final: ', output)\n",
    "    print('Structure 3: ', 2 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "    print('Generator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "        print('Generator output 4 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim, 32, 32])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl4\",\n",
    "        dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 4 final: ', output)\n",
    "    print('Structure 4: ', dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, 3, 5, output)\n",
    "    print('Generator output 6: ', output)\n",
    "    output = tf.tanh(output)\n",
    "    print('Generator output final: ', output)\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7ea79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prints removed\n",
    "# def kACGANGenerator(\n",
    "#     n_samples,\n",
    "#     numClasses,\n",
    "#     labels,\n",
    "#     noise=None,\n",
    "#     dim=DIM,\n",
    "#     bn=True,\n",
    "#     nonlinearity=tf.nn.relu,\n",
    "#     condition=None,\n",
    "# ):\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "#     if noise is None:\n",
    "#         noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "#     labels = tf.cast(labels, tf.float32)\n",
    "#     noise = tf.concat([noise, labels], 1)\n",
    "# #######################\n",
    "#     output = lib.ops.linear.Linear(\"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise)  \n",
    "#     output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False)\n",
    "#     condition = tf.reshape(condition, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = pixcnn_gated_nonlinearity(\"Generator.nl1\", 8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels)\n",
    "#     condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "#     output = pixcnn_gated_nonlinearity(\"Generator.nl2\", 4 * dim,output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels)\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim * 2, 16, 16])\n",
    "#     output = pixcnn_gated_nonlinearity( \"Generator.nl3\", 2 * dim,output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels)\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim, 32, 32])\n",
    "#     output = pixcnn_gated_nonlinearity(\"Generator.nl4\", dim,output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, 3, 5, output)\n",
    "#     output = tf.tanh(output)\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf3bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "\n",
    "#     sourceOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "#     )\n",
    "\n",
    "#     classOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "#     )\n",
    "\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b2eaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "#     output = nonlinearity(output)\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "# ######################\n",
    "#     sourceOutput = lib.ops.linear.Linear(\"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer)\n",
    "#     classOutput = lib.ops.linear.Linear(\"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer)\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7dc3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints removed\n",
    "def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "    output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "    print('Discriminator output 1: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 1 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "    print('Discriminator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "        print('Discriminator output 2 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 2 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "        print('Discriminator output 3 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 3 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "        print('Discriminator output 4 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 4 nonlinear: ', output)\n",
    "    finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "    print('Discriminator output final: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    sourceOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "    )\n",
    "    print('Discriminator source output: ', output)\n",
    "    classOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "    )\n",
    "    print('Discriminator class output: ', output)\n",
    "    print('#######################')\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "    return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f9a11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomLabels(n_samples, numClasses, condition=None):\n",
    "    labels = np.zeros([BATCH_SIZE, CLASSES], dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        if condition is not None:\n",
    "            labelNum = condition\n",
    "        else:\n",
    "            labelNum = randint(0, numClasses - 1)\n",
    "        labels[i, labelNum] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a63b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator, Discriminator = GeneratorAndDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8155b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ed99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started ...\n",
      "real_data:  Tensor(\"Reshape_46:0\", shape=(84, 12288), dtype=float32, device=/device:GPU:0)\n",
      "real_labels:  Tensor(\"Reshape_47:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "generated_labels:  Tensor(\"Reshape_48:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "sample_labels:  Tensor(\"Reshape_49:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "Generator output 1:  Tensor(\"Generator.Input_2/BiasAdd:0\", shape=(84, 16384), dtype=float32, device=/device:GPU:0) (84, 16384)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_50:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0) (84, 1024, 4, 4)\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3_8:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 final:  Tensor(\"mul_26:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Structure 1:  512 Tensor(\"strided_slice_69:0\", shape=(84, 256, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_70:0\", shape=(84, 256, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_71:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_72:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2_2/NHWC_to_NCHW:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_9:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 final:  Tensor(\"mul_27:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Structure 2:  256 Tensor(\"strided_slice_77:0\", shape=(84, 128, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_78:0\", shape=(84, 128, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_79:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_80:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3_2/NHWC_to_NCHW:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_10:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 final:  Tensor(\"mul_28:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Structure 3:  128 Tensor(\"strided_slice_85:0\", shape=(84, 64, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_86:0\", shape=(84, 64, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_87:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_88:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4_2/NHWC_to_NCHW:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_11:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 final:  Tensor(\"mul_29:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Structure 4:  64 Tensor(\"strided_slice_93:0\", shape=(84, 32, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_94:0\", shape=(84, 32, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_95:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_96:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 6:  Tensor(\"Generator.5_2/NHWC_to_NCHW:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Generator output final:  Tensor(\"Tanh_14:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "fake_data:  Tensor(\"Reshape_55:0\", shape=(84, 12288), dtype=float32, device=/device:GPU:0)\n",
      "fake_labels:  Tensor(\"Cast_6:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_3/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_12:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_3/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_9/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_13:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_3/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_10/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_14:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_3/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_11/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_15:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "disc fake:  Tensor(\"Reshape_64:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_65:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_4/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_16:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_4/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_12/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_17:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_4/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_13/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_18:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_4/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_14/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_19:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "disc real:  Tensor(\"Reshape_74:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_75:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "prediction 1:  Tensor(\"ArgMax_4:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_65:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 1:  Tensor(\"ArgMax_5:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Cast_6:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "equality 1:  Tensor(\"Equal_2:0\", shape=(84,), dtype=bool, device=/device:GPU:0)\n",
      "accuracy 1:  Tensor(\"Mean_11:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "prediction 2:  Tensor(\"ArgMax_6:0\", shape=(84,), dtype=int64, device=/device:GPU:0)\n",
      "disc real class:  Tensor(\"Reshape_75:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 2:  Tensor(\"ArgMax_7:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_47:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "equality 2:  Tensor(\"Equal_3:0\", shape=(84,), dtype=bool, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_5/BiasAdd:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_20:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_5/BiasAdd:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_15/add_1:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_21:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_5/BiasAdd:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_16/add_1:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_22:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_5/BiasAdd:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_17/add_1:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator class output:  Tensor(\"Maximum_23:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "#######################\n",
      "Generator output 1:  Tensor(\"Generator.Input_3/BiasAdd:0\", shape=(84, 16384), dtype=float32) (84, 16384)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_86:0\", shape=(84, 1024, 4, 4), dtype=float32) (84, 1024, 4, 4)\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3_12:0\", shape=(84, 1024, 4, 4), dtype=float32)\n",
      "Generator output 1 final:  Tensor(\"mul_46:0\", shape=(84, 512, 4, 4), dtype=float32)\n",
      "Structure 1:  512 Tensor(\"strided_slice_102:0\", shape=(84, 256, 4, 4), dtype=float32) Tensor(\"strided_slice_103:0\", shape=(84, 256, 4, 4), dtype=float32) Tensor(\"strided_slice_104:0\", shape=(84, 512, 4, 4), dtype=float32) Tensor(\"strided_slice_105:0\", shape=(84, 512, 4, 4), dtype=float32)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2_3/NHWC_to_NCHW:0\", shape=(84, 512, 8, 8), dtype=float32)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_13:0\", shape=(84, 512, 8, 8), dtype=float32)\n",
      "Generator output 2 final:  Tensor(\"mul_47:0\", shape=(84, 256, 8, 8), dtype=float32)\n",
      "Structure 2:  256 Tensor(\"strided_slice_110:0\", shape=(84, 128, 8, 8), dtype=float32) Tensor(\"strided_slice_111:0\", shape=(84, 128, 8, 8), dtype=float32) Tensor(\"strided_slice_112:0\", shape=(84, 256, 8, 8), dtype=float32) Tensor(\"strided_slice_113:0\", shape=(84, 256, 8, 8), dtype=float32)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3_3/NHWC_to_NCHW:0\", shape=(84, 256, 16, 16), dtype=float32)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_14:0\", shape=(84, 256, 16, 16), dtype=float32)\n",
      "Generator output 3 final:  Tensor(\"mul_48:0\", shape=(84, 128, 16, 16), dtype=float32)\n",
      "Structure 3:  128 Tensor(\"strided_slice_118:0\", shape=(84, 64, 16, 16), dtype=float32) Tensor(\"strided_slice_119:0\", shape=(84, 64, 16, 16), dtype=float32) Tensor(\"strided_slice_120:0\", shape=(84, 128, 16, 16), dtype=float32) Tensor(\"strided_slice_121:0\", shape=(84, 128, 16, 16), dtype=float32)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4_3/NHWC_to_NCHW:0\", shape=(84, 128, 32, 32), dtype=float32)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_15:0\", shape=(84, 128, 32, 32), dtype=float32)\n",
      "Generator output 4 final:  Tensor(\"mul_49:0\", shape=(84, 64, 32, 32), dtype=float32)\n",
      "Structure 4:  64 Tensor(\"strided_slice_126:0\", shape=(84, 32, 32, 32), dtype=float32) Tensor(\"strided_slice_127:0\", shape=(84, 32, 32, 32), dtype=float32) Tensor(\"strided_slice_128:0\", shape=(84, 64, 32, 32), dtype=float32) Tensor(\"strided_slice_129:0\", shape=(84, 64, 32, 32), dtype=float32)\n",
      "#######################\n",
      "Generator output 6:  Tensor(\"Generator.5_3/NHWC_to_NCHW:0\", shape=(84, 3, 64, 64), dtype=float32)\n",
      "Generator output final:  Tensor(\"Tanh_19:0\", shape=(84, 3, 64, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "pretraining accuracy: 0.6666667\n",
      "pretraining accuracy: 0.77380955\n",
      "pretraining accuracy: 0.79761904\n",
      "pretraining accuracy: 0.79761904\n",
      "pretraining accuracy: 0.86904764\n",
      "pretraining accuracy: 0.8452381\n",
      "pretraining accuracy: 0.75\n",
      "pretraining accuracy: 0.70238096\n",
      "pretraining accuracy: 0.64285713\n",
      "pretraining accuracy: 0.71428573\n",
      "pretraining accuracy: 0.6904762\n",
      "pretraining accuracy: 0.6785714\n",
      "pretraining accuracy: 0.75\n",
      "pretraining accuracy: 0.8095238\n",
      "pretraining accuracy: 0.8333333\n",
      "pretraining accuracy: 0.72619045\n",
      "pretraining accuracy: 0.78571427\n",
      "pretraining accuracy: 0.7380952\n",
      "pretraining accuracy: 0.53571427\n",
      "pretraining accuracy: 0.6904762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [41.0, 214.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [45.0, 214.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 0\ttrain disc cost\t-111.68348693847656\ttime\t4.888984203338623\twgan train disc cost\t-163.96417236328125\ttrain class cost\t0.5347051024436951\tgenerated class cost\t1.0305734872817993\tgen cost cost\t74.82097625732422\tgen accuracy\t0.380952388048172\treal accuracy\t0.6428571343421936\n",
      "iter 1\ttrain disc cost\t-108.31451416015625\ttime\t2.8601157665252686\twgan train disc cost\t-161.72454833984375\ttrain class cost\t0.540185272693634\tgenerated class cost\t0.9429410099983215\tgen cost cost\t74.34696197509766\tgen accuracy\t0.5\treal accuracy\t0.7142857313156128\n",
      "iter 2\ttrain disc cost\t-113.97610473632812\ttime\t1.37298583984375\twgan train disc cost\t-164.5698699951172\ttrain class cost\t0.5609886646270752\tgenerated class cost\t1.0514475107192993\tgen cost cost\t71.44355773925781\tgen accuracy\t0.4761904776096344\treal accuracy\t0.738095223903656\n",
      "iter 3\ttrain disc cost\t-109.38955688476562\ttime\t1.37229323387146\twgan train disc cost\t-169.45306396484375\ttrain class cost\t0.4735977053642273\tgenerated class cost\t0.8120101690292358\tgen cost cost\t68.74103546142578\tgen accuracy\t0.5476190447807312\treal accuracy\t0.773809552192688\n",
      "iter 4\ttrain disc cost\t-103.12470245361328\ttime\t1.3636455535888672\twgan train disc cost\t-163.73585510253906\ttrain class cost\t0.4593273401260376\tgenerated class cost\t1.1499152183532715\tgen cost cost\t56.51388168334961\tgen accuracy\t0.4761904776096344\treal accuracy\t0.7976190447807312\n",
      "iter 5\ttrain disc cost\t-102.74918365478516\ttime\t1.3611395359039307\twgan train disc cost\t-157.60806274414062\ttrain class cost\t0.5350876450538635\tgenerated class cost\t1.297792673110962\tgen cost cost\t58.041648864746094\tgen accuracy\t0.523809552192688\treal accuracy\t0.7023809552192688\n",
      "iter 6\ttrain disc cost\t-105.26844024658203\ttime\t1.362379789352417\twgan train disc cost\t-170.46273803710938\ttrain class cost\t0.5541331171989441\tgenerated class cost\t1.006194829940796\tgen cost cost\t64.53607177734375\tgen accuracy\t0.4761904776096344\treal accuracy\t0.738095223903656\n",
      "iter 7\ttrain disc cost\t-99.80843353271484\ttime\t1.3883953094482422\twgan train disc cost\t-167.52914428710938\ttrain class cost\t0.5690093040466309\tgenerated class cost\t1.1366591453552246\tgen cost cost\t53.35368347167969\tgen accuracy\t0.511904776096344\treal accuracy\t0.7023809552192688\n",
      "iter 8\ttrain disc cost\t-100.52713775634766\ttime\t1.3654098510742188\twgan train disc cost\t-161.0364990234375\ttrain class cost\t0.555724024772644\tgenerated class cost\t1.4403722286224365\tgen cost cost\t49.3403205871582\tgen accuracy\t0.523809552192688\treal accuracy\t0.761904776096344\n",
      "iter 9\ttrain disc cost\t-103.99732971191406\ttime\t1.3556468486785889\twgan train disc cost\t-164.70245361328125\ttrain class cost\t0.5446232557296753\tgenerated class cost\t1.837262511253357\tgen cost cost\t48.433406829833984\tgen accuracy\t0.4166666567325592\treal accuracy\t0.6904761791229248\n",
      "iter 99\ttrain disc cost\t-39.86634063720703\ttime\t1.399473081694709\twgan train disc cost\t-56.52631759643555\ttrain class cost\t0.5301697254180908\tgenerated class cost\t0.9067739844322205\tgen cost cost\t105.6932373046875\tgen accuracy\t0.5026454925537109\treal accuracy\t0.7334655523300171\tdev disc cost\t-13.11142349243164\twgan dev disc cost\t-17.521324157714844\tdev class cost\t0.49484342336654663\tdev generated class cost\t0.7708616852760315\tdev gen  cost\t133.3847198486328\tdev gen accuracy\t0.5595238208770752\tdev real accuracy\t0.75\n",
      "iter 199\ttrain disc cost\t-17.371118545532227\ttime\t1.4027223157882691\twgan train disc cost\t-23.062437057495117\ttrain class cost\t0.4738572835922241\tgenerated class cost\t0.7549899220466614\tgen cost cost\t129.37937927246094\tgen accuracy\t0.5339285731315613\treal accuracy\t0.7773810029029846\tdev disc cost\t-16.482093811035156\twgan dev disc cost\t-23.77959442138672\tdev class cost\t0.38373398780822754\tdev generated class cost\t0.6812579035758972\tdev gen  cost\t116.92636108398438\tdev gen accuracy\t0.5714285969734192\tdev real accuracy\t0.8690476417541504\n",
      "iter 299\ttrain disc cost\t-15.11512565612793\ttime\t1.401885449886322\twgan train disc cost\t-20.811752319335938\ttrain class cost\t0.4120832681655884\tgenerated class cost\t0.7438147068023682\tgen cost cost\t126.69503021240234\tgen accuracy\t0.598095178604126\treal accuracy\t0.8214285373687744\tdev disc cost\t-12.064962387084961\twgan dev disc cost\t-19.946029663085938\tdev class cost\t0.3124527335166931\tdev generated class cost\t0.9445803761482239\tdev gen  cost\t154.24911499023438\tdev gen accuracy\t0.6428571343421936\tdev real accuracy\t0.8452380895614624\n",
      "iter 399\ttrain disc cost\t-10.342242240905762\ttime\t1.4014173126220704\twgan train disc cost\t-13.159869194030762\ttrain class cost\t0.400101900100708\tgenerated class cost\t0.5137970447540283\tgen cost cost\t127.30827331542969\tgen accuracy\t0.7684524059295654\treal accuracy\t0.8191665410995483\tdev disc cost\t-8.612020492553711\twgan dev disc cost\t-10.558303833007812\tdev class cost\t0.3976268768310547\tdev generated class cost\t0.49966639280319214\tdev gen  cost\t132.38143920898438\tdev gen accuracy\t0.6904761791229248\tdev real accuracy\t0.8333333134651184\n",
      "iter 499\ttrain disc cost\t-8.64228630065918\ttime\t1.4011973547935486\twgan train disc cost\t-11.009147644042969\ttrain class cost\t0.34872210025787354\tgenerated class cost\t0.37862250208854675\tgen cost cost\t109.84754943847656\tgen accuracy\t0.8363094925880432\treal accuracy\t0.8507142066955566\tdev disc cost\t-10.34101676940918\twgan dev disc cost\t-13.653678894042969\tdev class cost\t0.26082244515419006\tdev generated class cost\t0.2974698543548584\tdev gen  cost\t87.54107666015625\tdev gen accuracy\t0.8928571343421936\tdev real accuracy\t0.8809523582458496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 599\ttrain disc cost\t-8.419503211975098\ttime\t1.401423349380493\twgan train disc cost\t-10.922669410705566\ttrain class cost\t0.3078243136405945\tgenerated class cost\t0.3503901958465576\tgen cost cost\t86.06873321533203\tgen accuracy\t0.8604761362075806\treal accuracy\t0.8798809051513672\tdev disc cost\t-9.079314231872559\twgan dev disc cost\t-11.607955932617188\tdev class cost\t0.2620603144168854\tdev generated class cost\t0.30733224749565125\tdev gen  cost\t80.11566162109375\tdev gen accuracy\t0.8690476417541504\tdev real accuracy\t0.9047619104385376\n",
      "iter 699\ttrain disc cost\t-8.079130172729492\ttime\t1.400338339805603\twgan train disc cost\t-10.39331340789795\ttrain class cost\t0.29047882556915283\tgenerated class cost\t0.282557874917984\tgen cost cost\t81.61091613769531\tgen accuracy\t0.9002380967140198\treal accuracy\t0.8903571367263794\tdev disc cost\t-6.99971866607666\twgan dev disc cost\t-9.420631408691406\tdev class cost\t0.4371476471424103\tdev generated class cost\t0.3545263111591339\tdev gen  cost\t63.2178840637207\tdev gen accuracy\t0.8571428656578064\tdev real accuracy\t0.8214285969734192\n",
      "iter 799\ttrain disc cost\t-6.401249408721924\ttime\t1.4033408212661742\twgan train disc cost\t-8.606245040893555\ttrain class cost\t0.2877150774002075\tgenerated class cost\t0.2035791575908661\tgen cost cost\t46.027191162109375\tgen accuracy\t0.9363095760345459\treal accuracy\t0.8869048357009888\tdev disc cost\t-8.95234489440918\twgan dev disc cost\t-12.240196228027344\tdev class cost\t0.2581287920475006\tdev generated class cost\t0.1033308357000351\tdev gen  cost\t51.076839447021484\tdev gen accuracy\t0.976190447807312\tdev real accuracy\t0.9166666865348816\n",
      "iter 899\ttrain disc cost\t-5.022747039794922\ttime\t1.401690788269043\twgan train disc cost\t-6.904908657073975\ttrain class cost\t0.27739766240119934\tgenerated class cost\t0.15977773070335388\tgen cost cost\t-8.912508964538574\tgen accuracy\t0.9553571939468384\treal accuracy\t0.8888095021247864\tdev disc cost\t-7.994810104370117\twgan dev disc cost\t-9.075313568115234\tdev class cost\t0.29691168665885925\tdev generated class cost\t0.09119025617837906\tdev gen  cost\t-32.65874481201172\tdev gen accuracy\t0.988095223903656\tdev real accuracy\t0.8928571343421936\n",
      "iter 999\ttrain disc cost\t-6.6820292472839355\ttime\t1.4035909223556517\twgan train disc cost\t-8.267999649047852\ttrain class cost\t0.23383809626102448\tgenerated class cost\t0.10017852485179901\tgen cost cost\t-6.544327259063721\tgen accuracy\t0.9794048070907593\treal accuracy\t0.9086905121803284\tdev disc cost\t-6.432538986206055\twgan dev disc cost\t-8.932722091674805\tdev class cost\t0.2715601921081543\tdev generated class cost\t0.08908609300851822\tdev gen  cost\t28.564664840698242\tdev gen accuracy\t0.9642857313156128\tdev real accuracy\t0.9047619104385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 1099\ttrain disc cost\t-6.684694766998291\ttime\t1.403406538963318\twgan train disc cost\t-8.672710418701172\ttrain class cost\t0.25139209628105164\tgenerated class cost\t0.09338913857936859\tgen cost cost\t21.982358932495117\tgen accuracy\t0.9838095307350159\treal accuracy\t0.9027382135391235\n",
      "iter 1199\ttrain disc cost\t-6.46151065826416\ttime\t1.4022132778167724\twgan train disc cost\t-8.562427520751953\ttrain class cost\t0.23636233806610107\tgenerated class cost\t0.09567563980817795\tgen cost cost\t20.07461166381836\tgen accuracy\t0.9815475344657898\treal accuracy\t0.9084524512290955\n",
      "iter 1299\ttrain disc cost\t-6.217940807342529\ttime\t1.4008592367172241\twgan train disc cost\t-8.016556739807129\ttrain class cost\t0.23118630051612854\tgenerated class cost\t0.09771106392145157\tgen cost cost\t-1.7776299715042114\tgen accuracy\t0.9758332967758179\treal accuracy\t0.9114285111427307\n",
      "iter 1399\ttrain disc cost\t-5.480712413787842\ttime\t1.4018301463127136\twgan train disc cost\t-6.952763080596924\ttrain class cost\t0.21262310445308685\tgenerated class cost\t0.08977150917053223\tgen cost cost\t-19.259090423583984\tgen accuracy\t0.9783334136009216\treal accuracy\t0.9166667461395264\n",
      "iter 1499\ttrain disc cost\t-5.751678466796875\ttime\t1.4022250032424928\twgan train disc cost\t-7.433149337768555\ttrain class cost\t0.2160448282957077\tgenerated class cost\t0.07423156499862671\tgen cost cost\t19.613567352294922\tgen accuracy\t0.9850000143051147\treal accuracy\t0.9182143211364746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 1599\ttrain disc cost\t-5.595407485961914\ttime\t1.4018380451202392\twgan train disc cost\t-7.108860492706299\ttrain class cost\t0.20306392014026642\tgenerated class cost\t0.07631437480449677\tgen cost cost\t42.6159553527832\tgen accuracy\t0.9850000143051147\treal accuracy\t0.9188095927238464\n",
      "iter 1699\ttrain disc cost\t-5.429957866668701\ttime\t1.4021496510505675\twgan train disc cost\t-7.007359504699707\ttrain class cost\t0.20227226614952087\tgenerated class cost\t0.07772807031869888\tgen cost cost\t44.45574188232422\tgen accuracy\t0.984285831451416\treal accuracy\t0.9233334064483643\n",
      "iter 1799\ttrain disc cost\t-5.322282791137695\ttime\t1.4013406443595886\twgan train disc cost\t-6.736286163330078\ttrain class cost\t0.19450968503952026\tgenerated class cost\t0.07967285811901093\tgen cost cost\t58.61565017700195\tgen accuracy\t0.9834524393081665\treal accuracy\t0.9266666173934937\n",
      "iter 1899\ttrain disc cost\t-5.305119037628174\ttime\t1.4025622820854187\twgan train disc cost\t-6.76054573059082\ttrain class cost\t0.19172149896621704\tgenerated class cost\t0.07754125446081161\tgen cost cost\t60.88627624511719\tgen accuracy\t0.9845238327980042\treal accuracy\t0.9269048571586609\n",
      "iter 1999\ttrain disc cost\t-4.901336669921875\ttime\t1.4019010376930237\twgan train disc cost\t-6.373608589172363\ttrain class cost\t0.19901318848133087\tgenerated class cost\t0.08525092154741287\tgen cost cost\t69.40995788574219\tgen accuracy\t0.9791667461395264\treal accuracy\t0.9235714077949524\tdev disc cost\t-6.756987571716309\twgan dev disc cost\t-7.562191009521484\tdev class cost\t0.13183146715164185\tdev generated class cost\t0.05444944649934769\tdev gen  cost\t60.952171325683594\tdev gen accuracy\t0.988095223903656\tdev real accuracy\t0.9642857313156128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 2099\ttrain disc cost\t-4.772975921630859\ttime\t1.402961664199829\twgan train disc cost\t-6.263311386108398\ttrain class cost\t0.19024871289730072\tgenerated class cost\t0.08712165057659149\tgen cost cost\t77.11013793945312\tgen accuracy\t0.9777381420135498\treal accuracy\t0.9308333396911621\n",
      "iter 2199\ttrain disc cost\t-4.654393672943115\ttime\t1.4035373663902282\twgan train disc cost\t-6.062150478363037\ttrain class cost\t0.19712568819522858\tgenerated class cost\t0.07771755009889603\tgen cost cost\t83.98837280273438\tgen accuracy\t0.981666624546051\treal accuracy\t0.9254761338233948\n",
      "iter 2299\ttrain disc cost\t-4.7488908767700195\ttime\t1.40259348154068\twgan train disc cost\t-6.1775360107421875\ttrain class cost\t0.19003035128116608\tgenerated class cost\t0.07747242599725723\tgen cost cost\t90.72261810302734\tgen accuracy\t0.9834523797035217\treal accuracy\t0.9297619462013245\n",
      "iter 2399\ttrain disc cost\t-4.497307300567627\ttime\t1.4035864520072936\twgan train disc cost\t-5.975342273712158\ttrain class cost\t0.20070157945156097\tgenerated class cost\t0.07002659142017365\tgen cost cost\t96.06591033935547\tgen accuracy\t0.9877381324768066\treal accuracy\t0.9245238304138184\n",
      "iter 2499\ttrain disc cost\t-4.29661750793457\ttime\t1.401752142906189\twgan train disc cost\t-5.664289951324463\ttrain class cost\t0.1876772940158844\tgenerated class cost\t0.07697758078575134\tgen cost cost\t94.8747329711914\tgen accuracy\t0.9820239543914795\treal accuracy\t0.9228572249412537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 2599\ttrain disc cost\t-4.2903642654418945\ttime\t1.4028959321975707\twgan train disc cost\t-5.615362644195557\ttrain class cost\t0.18552011251449585\tgenerated class cost\t0.07104286551475525\tgen cost cost\t91.88667297363281\tgen accuracy\t0.9838095903396606\treal accuracy\t0.9303571581840515\n",
      "iter 2699\ttrain disc cost\t-4.061801910400391\ttime\t1.401220326423645\twgan train disc cost\t-5.400393009185791\ttrain class cost\t0.1844145655632019\tgenerated class cost\t0.06462766975164413\tgen cost cost\t94.67192077636719\tgen accuracy\t0.9854762554168701\treal accuracy\t0.9276190996170044\n",
      "iter 2799\ttrain disc cost\t-4.191708564758301\ttime\t1.402883265018463\twgan train disc cost\t-5.374474048614502\ttrain class cost\t0.18397153913974762\tgenerated class cost\t0.06919382512569427\tgen cost cost\t101.22164154052734\tgen accuracy\t0.9859524369239807\treal accuracy\t0.9288095235824585\n",
      "iter 2899\ttrain disc cost\t-4.081202507019043\ttime\t1.40410147190094\twgan train disc cost\t-5.281680107116699\ttrain class cost\t0.19092947244644165\tgenerated class cost\t0.06539027392864227\tgen cost cost\t93.79010772705078\tgen accuracy\t0.9872618913650513\treal accuracy\t0.925000011920929\n",
      "iter 2999\ttrain disc cost\t-4.252359867095947\ttime\t1.402405776977539\twgan train disc cost\t-5.347348213195801\ttrain class cost\t0.18017560243606567\tgenerated class cost\t0.060006290674209595\tgen cost cost\t94.6257553100586\tgen accuracy\t0.9895239472389221\treal accuracy\t0.9315477609634399\tdev disc cost\t-3.461210250854492\twgan dev disc cost\t-4.2498779296875\tdev class cost\t0.17277070879936218\tdev generated class cost\t0.046036649495363235\tdev gen  cost\t95.66761779785156\tdev gen accuracy\t0.988095223903656\tdev real accuracy\t0.9166666865348816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 3099\ttrain disc cost\t-3.3963184356689453\ttime\t1.4011079812049865\twgan train disc cost\t-4.93528413772583\ttrain class cost\t0.203330859541893\tgenerated class cost\t0.06405656784772873\tgen cost cost\t70.93272399902344\tgen accuracy\t0.9854762554168701\treal accuracy\t0.9227381348609924\n",
      "iter 3199\ttrain disc cost\t-3.822298049926758\ttime\t1.4008674311637879\twgan train disc cost\t-5.001318454742432\ttrain class cost\t0.18475879728794098\tgenerated class cost\t0.054322611540555954\tgen cost cost\t71.0983657836914\tgen accuracy\t0.9905953407287598\treal accuracy\t0.9241665601730347\n",
      "iter 3299\ttrain disc cost\t-3.9833927154541016\ttime\t1.4009272789955138\twgan train disc cost\t-5.16493034362793\ttrain class cost\t0.18063880503177643\tgenerated class cost\t0.057910725474357605\tgen cost cost\t77.83146667480469\tgen accuracy\t0.9878571033477783\treal accuracy\t0.9314286112785339\n",
      "iter 3399\ttrain disc cost\t-3.820455551147461\ttime\t1.4010612201690673\twgan train disc cost\t-4.779977321624756\ttrain class cost\t0.17817334830760956\tgenerated class cost\t0.055129896849393845\tgen cost cost\t87.44237518310547\tgen accuracy\t0.9919047355651855\treal accuracy\t0.9317857623100281\n",
      "iter 3499\ttrain disc cost\t-3.7935791015625\ttime\t1.400926697254181\twgan train disc cost\t-4.85257625579834\ttrain class cost\t0.17843422293663025\tgenerated class cost\t0.049681805074214935\tgen cost cost\t88.16283416748047\tgen accuracy\t0.994642972946167\treal accuracy\t0.9294048547744751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 3599\ttrain disc cost\t-3.6810357570648193\ttime\t1.4023814249038695\twgan train disc cost\t-4.744772434234619\ttrain class cost\t0.17781351506710052\tgenerated class cost\t0.0572144091129303\tgen cost cost\t95.81140899658203\tgen accuracy\t0.9907143115997314\treal accuracy\t0.929523766040802\n",
      "iter 3699\ttrain disc cost\t-3.7295584678649902\ttime\t1.4005552268028258\twgan train disc cost\t-4.682353496551514\ttrain class cost\t0.17932960391044617\tgenerated class cost\t0.05282359570264816\tgen cost cost\t102.82147216796875\tgen accuracy\t0.992023766040802\treal accuracy\t0.9301190972328186\n",
      "iter 3799\ttrain disc cost\t-3.511425495147705\ttime\t1.4026203441619873\twgan train disc cost\t-4.403751850128174\ttrain class cost\t0.1748310923576355\tgenerated class cost\t0.05260523408651352\tgen cost cost\t98.32406616210938\tgen accuracy\t0.9910714030265808\treal accuracy\t0.9303572177886963\n",
      "iter 3899\ttrain disc cost\t-3.709559917449951\ttime\t1.4023644232749939\twgan train disc cost\t-4.752697467803955\ttrain class cost\t0.1716962456703186\tgenerated class cost\t0.048825617879629135\tgen cost cost\t95.03842163085938\tgen accuracy\t0.9919048547744751\treal accuracy\t0.9340476393699646\n",
      "iter 3999\ttrain disc cost\t-3.525449275970459\ttime\t1.402732949256897\twgan train disc cost\t-4.409274578094482\ttrain class cost\t0.1800185590982437\tgenerated class cost\t0.05238097161054611\tgen cost cost\t103.66476440429688\tgen accuracy\t0.9908333420753479\treal accuracy\t0.9280952215194702\tdev disc cost\t-2.1486830711364746\twgan dev disc cost\t-3.3532562255859375\tdev class cost\t0.19707082211971283\tdev generated class cost\t0.06608238816261292\tdev gen  cost\t109.79681396484375\tdev gen accuracy\t0.988095223903656\tdev real accuracy\t0.9166666865348816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 4099\ttrain disc cost\t-3.3186700344085693\ttime\t1.4024268245697022\twgan train disc cost\t-4.499382019042969\ttrain class cost\t0.16596508026123047\tgenerated class cost\t0.05213691294193268\tgen cost cost\t103.27690124511719\tgen accuracy\t0.9922619462013245\treal accuracy\t0.9359524250030518\n",
      "iter 4199\ttrain disc cost\t-3.4977409839630127\ttime\t1.4039298748970033\twgan train disc cost\t-4.40006160736084\ttrain class cost\t0.17748241126537323\tgenerated class cost\t0.04797852039337158\tgen cost cost\t97.15032958984375\tgen accuracy\t0.9942857623100281\treal accuracy\t0.9354762434959412\n",
      "iter 4299\ttrain disc cost\t-1.6905125379562378\ttime\t1.4030592012405396\twgan train disc cost\t-2.769390344619751\ttrain class cost\t0.23029857873916626\tgenerated class cost\t0.11329082399606705\tgen cost cost\t33.7291259765625\tgen accuracy\t0.972261905670166\treal accuracy\t0.9080953001976013\n",
      "iter 4399\ttrain disc cost\t-2.2980833053588867\ttime\t1.4028494954109192\twgan train disc cost\t-2.78041934967041\ttrain class cost\t0.23324303328990936\tgenerated class cost\t0.08299697190523148\tgen cost cost\t-33.903499603271484\tgen accuracy\t0.9872618317604065\treal accuracy\t0.9064286947250366\n",
      "iter 4499\ttrain disc cost\t-2.1066040992736816\ttime\t1.4016463112831117\twgan train disc cost\t-2.6020290851593018\ttrain class cost\t0.21214956045150757\tgenerated class cost\t0.05113595351576805\tgen cost cost\t-48.620849609375\tgen accuracy\t0.9916667342185974\treal accuracy\t0.9178571105003357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "iter 4599\ttrain disc cost\t-2.5061216354370117\ttime\t1.3986227369308473\twgan train disc cost\t-3.074136972427368\ttrain class cost\t0.20545679330825806\tgenerated class cost\t0.05418659374117851\tgen cost cost\t-42.84840774536133\tgen accuracy\t0.9914286732673645\treal accuracy\t0.9194048047065735\n",
      "iter 4699\ttrain disc cost\t-2.5665276050567627\ttime\t1.3981501460075378\twgan train disc cost\t-3.147723436355591\ttrain class cost\t0.19513282179832458\tgenerated class cost\t0.04553757235407829\tgen cost cost\t-32.66179656982422\tgen accuracy\t0.9920238256454468\treal accuracy\t0.9285716414451599\n",
      "iter 4799\ttrain disc cost\t-2.8726446628570557\ttime\t1.3988108468055724\twgan train disc cost\t-3.5071778297424316\ttrain class cost\t0.18691696226596832\tgenerated class cost\t0.04513956978917122\tgen cost cost\t-24.101537704467773\tgen accuracy\t0.9916667342185974\treal accuracy\t0.9323810338973999\n",
      "iter 4899\ttrain disc cost\t-2.8069727420806885\ttime\t1.3994714975357057\twgan train disc cost\t-3.5112204551696777\ttrain class cost\t0.1910748928785324\tgenerated class cost\t0.049915704876184464\tgen cost cost\t-19.931198120117188\tgen accuracy\t0.9898809790611267\treal accuracy\t0.9278572201728821\n",
      "iter 4999\ttrain disc cost\t-2.977893590927124\ttime\t1.3993639850616455\twgan train disc cost\t-3.6652252674102783\ttrain class cost\t0.17856638133525848\tgenerated class cost\t0.04070357233285904\tgen cost cost\t-21.317039489746094\tgen accuracy\t0.994642972946167\treal accuracy\t0.932976245880127\tdev disc cost\t-4.652364730834961\twgan dev disc cost\t-5.379633903503418\tdev class cost\t0.26274925470352173\tdev generated class cost\t0.08081622421741486\tdev gen  cost\t-8.339232444763184\tdev gen accuracy\t0.976190447807312\tdev real accuracy\t0.8928571343421936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n",
    "    print('started ...')\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, DIM, DIM])\n",
    "    all_real_label_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    generated_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "    sample_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n",
    "    split_real_label_conv = tf.split(all_real_label_conv, len(DEVICES))\n",
    "    split_generated_labels_conv = tf.split(generated_labels_conv, len(DEVICES))\n",
    "    split_sample_labels_conv = tf.split(sample_labels_conv, len(DEVICES))\n",
    "\n",
    "    gen_costs, disc_costs = [], []\n",
    "\n",
    "    for device_index, (device, real_data_conv, real_label_conv) in enumerate(\n",
    "        zip(DEVICES, split_real_data_conv, split_real_label_conv)\n",
    "    ):\n",
    "        with tf.device(device):\n",
    "\n",
    "            real_data = tf.reshape(\n",
    "                2 * ((tf.cast(real_data_conv, tf.float32) / 255.0) - 0.5),\n",
    "                [BATCH_SIZE // len(DEVICES), OUTPUT_DIM],\n",
    "            )\n",
    "            print('real_data: ', real_data)\n",
    "            real_labels = tf.reshape(\n",
    "                real_label_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('real_labels: ', real_labels)\n",
    "            generated_labels = tf.reshape(\n",
    "                split_generated_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('generated_labels: ', generated_labels)\n",
    "            sample_labels = tf.reshape(\n",
    "                split_sample_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('sample_labels: ', sample_labels)\n",
    "            fake_data, fake_labels = Generator(\n",
    "                BATCH_SIZE // len(DEVICES), CLASSES, generated_labels\n",
    "            )\n",
    "#             print(real_data,real_labels,generated_labels,sample_labels,fake_data, fake_labels)\n",
    "            print('fake_data: ', fake_data)\n",
    "            print('fake_labels: ', fake_labels)\n",
    "            # set up discrimnator results\n",
    "\n",
    "            disc_fake, disc_fake_class = Discriminator(fake_data, CLASSES)\n",
    "            print('disc fake: ', disc_fake, disc_fake_class)\n",
    "            disc_real, disc_real_class = Discriminator(real_data, CLASSES)\n",
    "            print('disc real: ', disc_real, disc_real_class)\n",
    "            prediction = tf.argmax(disc_fake_class, 1)\n",
    "            print('prediction 1: ', prediction, disc_fake_class)\n",
    "            correct_answer = tf.argmax(fake_labels, 1)\n",
    "            print('correct 1: ', correct_answer, fake_labels)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 1: ', equality)\n",
    "            genAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            print('accuracy 1: ', genAccuracy)\n",
    "            \n",
    "            prediction = tf.argmax(disc_real_class, 1)\n",
    "            print('prediction 2: ', prediction)\n",
    "            print('disc real class: ', disc_real_class)\n",
    "            correct_answer = tf.argmax(real_labels, 1)\n",
    "            print('correct 2: ', correct_answer, real_labels)\n",
    "#             equality = tf.equal(correct_answer, prediction)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 2: ', equality)\n",
    "            realAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "            gen_cost = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            gen_cost_test = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost_test = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            generated_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_fake_class, labels=fake_labels\n",
    "                )\n",
    "            )\n",
    "\n",
    "            real_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_real_class, labels=real_labels\n",
    "                )\n",
    "            )\n",
    "            gen_cost += generated_class_cost\n",
    "            disc_cost += real_class_cost\n",
    "\n",
    "            alpha = tf.random_uniform(\n",
    "                shape=[BATCH_SIZE // len(DEVICES), 1], minval=0.0, maxval=1.0\n",
    "            )\n",
    "            differences = fake_data - real_data\n",
    "            interpolates = real_data + (alpha * differences)\n",
    "            gradients = tf.gradients(\n",
    "                Discriminator(interpolates, CLASSES)[0], [interpolates]\n",
    "            )[0]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes - 1.0) ** 2)\n",
    "            disc_cost += LAMBDA * gradient_penalty\n",
    "\n",
    "            real_class_cost_gradient = real_class_cost * 50 + LAMBDA * gradient_penalty\n",
    "\n",
    "            gen_costs.append(gen_cost)\n",
    "            disc_costs.append(disc_cost)\n",
    "\n",
    "    gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "    disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
    "\n",
    "    gen_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        gen_cost,\n",
    "        var_list=lib.params_with_name(\"Generator\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    disc_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        disc_cost,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    class_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        real_class_cost_gradient,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    # For generating samples\n",
    "\n",
    "    fixed_noise = tf.constant(\n",
    "        np.random.normal(size=(BATCH_SIZE, 128)).astype(\"float32\")\n",
    "    )\n",
    "    all_fixed_noise_samples = []\n",
    "    for device_index, device in enumerate(DEVICES):\n",
    "        n_samples = BATCH_SIZE // len(DEVICES)\n",
    "        all_fixed_noise_samples.append(\n",
    "            Generator(\n",
    "                n_samples,\n",
    "                CLASSES,\n",
    "                sample_labels,\n",
    "                noise=fixed_noise[\n",
    "                    device_index * n_samples : (device_index + 1) * n_samples\n",
    "                ],\n",
    "            )[0]\n",
    "        )\n",
    "        if tf.__version__.startswith(\"1.\"):\n",
    "            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n",
    "        else:\n",
    "            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
    "\n",
    "    def generate_image(iteration):\n",
    "        # this might be where we add the conditionality\n",
    "        for i in range(CLASSES):\n",
    "            curLabel = genRandomLabels(BATCH_SIZE, CLASSES, condition=i)\n",
    "            samples = session.run(\n",
    "                all_fixed_noise_samples, feed_dict={sample_labels: curLabel}\n",
    "            )\n",
    "            samples = ((samples + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "            lib.save_images.save_images(\n",
    "                samples.reshape((BATCH_SIZE, 3, DIM, DIM)),\n",
    "                \"generated/samples_{}_{}.png\".format(str(i), iteration),\n",
    "            )\n",
    "\n",
    "    # Dataset iterator\n",
    "#     train_gen, dev_gen = lib.wikiart_genre.load(BATCH_SIZE)\n",
    "    train_gen, dev_gen = load(BATCH_SIZE)\n",
    "\n",
    "    def softmax_cross_entropy(logit, y):\n",
    "        return -tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y)\n",
    "        )\n",
    "\n",
    "    def inf_train_gen():\n",
    "        while True:\n",
    "            for (images, labels) in train_gen():\n",
    "                yield images, labels\n",
    "\n",
    "    _sample_labels = genRandomLabels(BATCH_SIZE, CLASSES)\n",
    "    # Save a batch of ground-truth samples\n",
    "    _x, _y = next(train_gen())\n",
    "    _x_r = session.run(real_data, feed_dict={all_real_data_conv: _x})\n",
    "    _x_r = ((_x_r + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "    lib.save_images.save_images(\n",
    "        _x_r.reshape((BATCH_SIZE, 3, DIM, DIM)), \"generated/samples_groundtruth.png\"\n",
    "    )\n",
    "\n",
    "    session.run(\n",
    "        tf.initialize_all_variables(),\n",
    "        feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "    )\n",
    "    gen = train_gen()\n",
    "\n",
    "    for iterp in range(PREITERATIONS):\n",
    "        _data, _labels = next(gen)\n",
    "        _, accuracy = session.run(\n",
    "            [disc_train_op, realAccuracy],\n",
    "            feed_dict={\n",
    "                all_real_data_conv: _data,\n",
    "                all_real_label_conv: _labels,\n",
    "                generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "            },\n",
    "        )\n",
    "        if iterp % 100 == 99:\n",
    "            print(\"pretraining accuracy: \" + str(accuracy))\n",
    "\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(\n",
    "                gen_train_op,\n",
    "                feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "            )\n",
    "        # Train critic\n",
    "        disc_iters = CRITIC_ITERS\n",
    "        for i in range(disc_iters):\n",
    "            _data, _labels = next(gen)\n",
    "            (\n",
    "                _disc_cost,\n",
    "                _disc_cost_test,\n",
    "                class_cost_test,\n",
    "                gen_class_cost,\n",
    "                _gen_cost_test,\n",
    "                _genAccuracy,\n",
    "                _realAccuracy,\n",
    "                _,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                    disc_train_op,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: _data,\n",
    "                    all_real_label_conv: _labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "\n",
    "        lib.plot.plot(\"train disc cost\", _disc_cost)\n",
    "        lib.plot.plot(\"time\", time.time() - start_time)\n",
    "        lib.plot.plot(\"wgan train disc cost\", _disc_cost_test)\n",
    "        lib.plot.plot(\"train class cost\", class_cost_test)\n",
    "        lib.plot.plot(\"generated class cost\", gen_class_cost)\n",
    "        lib.plot.plot(\"gen cost cost\", _gen_cost_test)\n",
    "        lib.plot.plot(\"gen accuracy\", _genAccuracy)\n",
    "        lib.plot.plot(\"real accuracy\", _realAccuracy)\n",
    "\n",
    "        if (iteration % 100 == 99 and iteration < 1000) or iteration % 1000 == 999:\n",
    "            t = time.time()\n",
    "            dev_disc_costs = []\n",
    "            images, labels = next(dev_gen())\n",
    "            (\n",
    "                _dev_disc_cost,\n",
    "                _dev_disc_cost_test,\n",
    "                _class_cost_test,\n",
    "                _gen_class_cost,\n",
    "                _dev_gen_cost_test,\n",
    "                _dev_genAccuracy,\n",
    "                _dev_realAccuracy,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: images,\n",
    "                    all_real_label_conv: labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot(\"dev disc cost\", np.mean(dev_disc_costs))\n",
    "            lib.plot.plot(\"wgan dev disc cost\", _dev_disc_cost_test)\n",
    "            lib.plot.plot(\"dev class cost\", _class_cost_test)\n",
    "            lib.plot.plot(\"dev generated class cost\", _gen_class_cost)\n",
    "            lib.plot.plot(\"dev gen  cost\", _dev_gen_cost_test)\n",
    "            lib.plot.plot(\"dev gen accuracy\", _dev_genAccuracy)\n",
    "            lib.plot.plot(\"dev real accuracy\", _dev_realAccuracy)\n",
    "\n",
    "        if iteration % 500 == 0:\n",
    "            generate_image(iteration)\n",
    "            # Can add generate_good_images method in here if desired\n",
    "\n",
    "        if (iteration < 10) or (iteration % 100 == 99):\n",
    "            lib.plot.flush()\n",
    "\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68db569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70ce47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2e8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
