{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573c3f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87672616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38478535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d042d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimension of images you want to be passed in to the network\n",
    "DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d74613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your own path to images\n",
    "# src_img_path  = Path('/home/ec2-user/SageMaker/genre-128')\n",
    "src_img_path  = Path('/home/ec2-user/SageMaker/portrait_landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0e1f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(src_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b703d7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14971"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(src_img_path,'1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f21a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary should be updated to hold the absolute number of images associated with each genre used during training\n",
    "styles = {\n",
    "    \"portraits\": 14981,\n",
    "    \"landscapes\": 14971\n",
    "}\n",
    "\n",
    "styleNum = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 1\n",
    "}\n",
    "    \n",
    "curPos = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be1bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNums = {}\n",
    "trainNums = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e01d15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set of images made up of 1/20 of the images (per genre)\n",
    "for k, v in styles.items():\n",
    "    # put a twentieth of paintings in here\n",
    "    nums = range(v)\n",
    "    random.shuffle(list(nums))\n",
    "    testNums[k] = nums[0 : v // 20]\n",
    "    trainNums[k] = nums[v // 20 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32982bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'portraits': range(749, 14981), 'landscapes': range(748, 14971)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c918e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_gen(gen):\n",
    "    while True:\n",
    "        for (images, labels) in gen():\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a7c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(files, batch_size, n_classes): # add genre parameter\n",
    "    if batch_size % n_classes != 0:\n",
    "        raise ValueError(\n",
    "            \"Batch size {} must be divisible by num classes {}\".format(batch_size, n_classes)\n",
    "        )\n",
    "\n",
    "    class_batch = batch_size // n_classes\n",
    "\n",
    "    generators = []\n",
    "\n",
    "    def get_epoch():\n",
    "\n",
    "        while True:\n",
    "\n",
    "            images = np.zeros((batch_size, 3, DIM, DIM), dtype=\"int32\")\n",
    "            labels = np.zeros((batch_size, n_classes))\n",
    "            n = 0\n",
    "            for style in styles:\n",
    "#             for style in genre:\n",
    "                styleLabel = styleNum[style]\n",
    "                curr = curPos[style]\n",
    "                for _ in range(class_batch):\n",
    "                    if curr == styles[style]:\n",
    "                        curr = 0\n",
    "                        random.shuffle(list(files[style]))\n",
    "                    img_path = str(Path(src_img_path, str(styleLabel), str(curr) + \".png\"))\n",
    "                    image = Image.open(img_path).convert(mode=\"RGB\")\n",
    "                    image = np.asarray(image)\n",
    "\n",
    "                    images[n % batch_size] = image.transpose(2, 0, 1)\n",
    "                    labels[n % batch_size, int(styleLabel)] = 1\n",
    "                    n += 1\n",
    "                    curr += 1\n",
    "                curPos[style] = curr\n",
    "\n",
    "            # randomize things but keep relationship between a conditioning vector and its associated image\n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.shuffle(images)\n",
    "            np.random.set_state(rng_state)\n",
    "            np.random.shuffle(labels)\n",
    "            yield (images, labels)\n",
    "\n",
    "    return get_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c82f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size):\n",
    "    return (\n",
    "        make_generator(trainNums, batch_size, len(styles)),\n",
    "        make_generator(testNums, batch_size, len(styles)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d201b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "# import tflib.wikiart_genre\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f56705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91192f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cff7ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfa82d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3be082d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 84\n",
      "\tCLASSES: 2\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDIM: 128\n",
      "\tITERS: 200000\n",
      "\tLAMBDA: 10\n",
      "\tMODE: acwgan\n",
      "\tN_GPUS: 1\n",
      "\tOUTPUT_DIM: 49152\n",
      "\tPREITERATIONS: 2000\n"
     ]
    }
   ],
   "source": [
    "MODE = \"acwgan\"  # dcgan, wgan, wgan-gp, lsgan\n",
    "genre = ['portraits','landscapes']\n",
    "DIM = 128  # Model dimensionality\n",
    "CRITIC_ITERS = 5  # How many iterations to train the critic for, increase it to 50 later\n",
    "N_GPUS = 1  # Number of GPUs\n",
    "BATCH_SIZE = 84  # Batch size. Must be a multiple of CLASSES and N_GPUS\n",
    "ITERS = 200000  # How many iterations to train for\n",
    "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = DIM * DIM * 3  # Number of pixels in each image\n",
    "CLASSES = len(genre)  # Number of classes, for genres probably 14\n",
    "PREITERATIONS = 2000  # Number of preiteration training cycles to run\n",
    "lib.print_model_settings(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c639885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that directory exists where ground truth and plots will be saved to.\n",
    "Path('generated').mkdir(parents=True, exist_ok=True)\n",
    "Path('models').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98a19cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratorAndDiscriminator():\n",
    "    return kACGANGenerator, kACGANDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc1d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [\"/gpu:{}\".format(i) for i in range(N_GPUS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd3b5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha * x, x)\n",
    "\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "\n",
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return LeakyReLU(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d40c08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batchnorm(name, axes, inputs):\n",
    "\n",
    "    if (\"Discriminator\" in name) and (MODE == \"wgan-gp\" or MODE == \"acwgan\"):\n",
    "        if axes != [0, 2, 3]:\n",
    "            raise Exception(\"Layernorm over non-standard axes is unsupported\")\n",
    "        return lib.ops.layernorm.Layernorm(name, [1, 2, 3], inputs)\n",
    "    else:\n",
    "        return lib.ops.batchnorm.Batchnorm(name, axes, inputs, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88964895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixcnn_gated_nonlinearity(name, output_dim, a, b, c=None, d=None):\n",
    "    if c is not None and d is not None:\n",
    "        a = a + c\n",
    "        b = b + d\n",
    "\n",
    "    result = tf.sigmoid(a) * tf.tanh(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04a4be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubpixelConv2D(*args, **kwargs):\n",
    "    kwargs[\"output_dim\"] = 4 * kwargs[\"output_dim\"]\n",
    "    output = lib.ops.conv2d.Conv2D(*args, **kwargs)\n",
    "    output = tf.transpose(output, [0, 2, 3, 1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0, 3, 1, 2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9fcbef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(\n",
    "    name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True\n",
    "):\n",
    "    \"\"\"\n",
    "    resample: None, 'down', or 'up'\n",
    "    \"\"\"\n",
    "    if resample == \"down\":\n",
    "        conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "            stride=2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == \"up\":\n",
    "        conv_shortcut = SubpixelConv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.deconv2d.Deconv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == None:\n",
    "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim // 2\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"invalid resample value\")\n",
    "\n",
    "    if output_dim == input_dim and resample == None:\n",
    "        shortcut = inputs  # Identity skip-connection\n",
    "    else:\n",
    "        shortcut = conv_shortcut(\n",
    "            name + \".Shortcut\",\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            filter_size=1,\n",
    "            he_init=False,\n",
    "            biases=True,\n",
    "            inputs=inputs,\n",
    "        )\n",
    "\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1(\n",
    "        name + \".Conv1\", filter_size=1, inputs=output, he_init=he_init, weightnorm=False\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1b(\n",
    "        name + \".Conv1B\",\n",
    "        filter_size=filter_size,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_2(\n",
    "        name + \".Conv2\",\n",
    "        filter_size=1,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "        biases=False,\n",
    "    )\n",
    "    output = Batchnorm(name + \".BN\", [0, 2, 3], output)\n",
    "\n",
    "    return shortcut + (0.3 * output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83e9de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANGenerator(\n",
    "#     n_samples,\n",
    "#     numClasses,\n",
    "#     labels,\n",
    "#     noise=None,\n",
    "#     dim=DIM,\n",
    "#     bn=True,\n",
    "#     nonlinearity=tf.nn.relu,\n",
    "#     condition=None,\n",
    "# ):\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "#     if noise is None:\n",
    "#         noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "#     labels = tf.cast(labels, tf.float32)\n",
    "#     noise = tf.concat([noise, labels], 1)\n",
    "\n",
    "#     output = lib.ops.linear.Linear(\n",
    "#         \"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise\n",
    "#     )  # probs need to recalculate dimensions\n",
    "#     print('output 1: ', output)\n",
    "#     output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "# #     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "#     print('output 2: ', output, output.shape)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl1\",\n",
    "#         8 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl2\",\n",
    "#         4 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim * 2, 16, 16])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl3\",\n",
    "#         2 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, dim * 2, 32, 32])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl4\",\n",
    "#         dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, 3, 5, output)\n",
    "\n",
    "#     output = tf.tanh(output)\n",
    "\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "914654bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANGenerator(\n",
    "#     n_samples,\n",
    "#     numClasses,\n",
    "#     labels,\n",
    "#     noise=None,\n",
    "#     dim=DIM,\n",
    "#     bn=True,\n",
    "#     nonlinearity=tf.nn.relu,\n",
    "#     condition=None,\n",
    "# ):\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "#     if noise is None:\n",
    "#         noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "#     labels = tf.cast(labels, tf.float32)\n",
    "#     noise = tf.concat([noise, labels], 1)\n",
    "\n",
    "#     output = lib.ops.linear.Linear(\n",
    "#         \"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise\n",
    "#     )  # probs need to recalculate dimensions\n",
    "#     print('Generator output 1: ', output)\n",
    "#     output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "# #     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "#     print('Generator output 1 reshape: ', output, output.shape)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "#         print('Generator output 1 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl1\",\n",
    "#         8 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 1 final: ', output)\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "#     print('Generator output 2: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "#         print('Generator output 2 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl2\",\n",
    "#         4 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 2 final: ', output)\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "#     print('Generator output 3: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "#         print('Generator output 3 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim * 2, 16, 16])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl3\",\n",
    "#         2 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 3 final: ', output)\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "#     print('Generator output 4: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "#         print('Generator output 4 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim * 2, 32, 32])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl4\",\n",
    "#         dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 4 final: ', output)\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", dim, dim , 5, output)\n",
    "#     print('Generator output 5: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "#         print('Generator output 5 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond4\", numClasses, 32 * 64 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, dim , 64, 64])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl4\",\n",
    "#         dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 5 final: ', output)\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, 3, 5, output)\n",
    "#     print('Generator output 6: ', output)\n",
    "#     output = tf.tanh(output)\n",
    "#     print('Generator output final: ', output)\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "336607d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim, 2 * dim, 5, output, stride=2)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.3\", 2 * dim, 4 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.4\", 4 * dim, 8 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#     output = nonlinearity(output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "\n",
    "#     sourceOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "#     )\n",
    "\n",
    "#     classOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "#     )\n",
    "\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9c62026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "#     print('Discriminator output 1: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 1 nonlinear: ', output)\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim //2,  2 * dim//2, 5, output, stride=2)\n",
    "#     print('Discriminator output 2: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 2 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 2 nonlinear: ', output)\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.3\", 2 * dim//2,  4 * dim//2, 5, output, stride=2\n",
    "#     )\n",
    "#     print('Discriminator output 3: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 3 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 3 nonlinear: ', output)\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.4\", 4 * dim//2,  8 * dim//2, 5, output, stride=2\n",
    "#     )\n",
    "#     print('Discriminator output 4: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 4 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 4 nonlinear: ', output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "#     print('Discriminator output final: ', output)\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "# #     output = lib.ops.conv2d.Conv2D(\n",
    "# #         \"Discriminator.5\", 8 * dim, 16 * dim, 5, output, stride=2\n",
    "# #     )\n",
    "# #     print('Discriminator output 5: ', output)\n",
    "# #     if bn:\n",
    "# #         output = Batchnorm(\"Discriminator.BN5\", [0, 2, 3], output)\n",
    "# #         print('Discriminator output 5 bn: ', output)\n",
    "# #     output = nonlinearity(output)\n",
    "# #     print('Discriminator output 5 nonlinear: ', output)\n",
    "# #     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "# #     print('Discriminator output final: ', output)\n",
    "# #     print('#######################')\n",
    "# ######################\n",
    "#     sourceOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "#     )\n",
    "#     print('Discriminator source output: ', output)\n",
    "#     classOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "#     )\n",
    "#     print('Discriminator class output: ', output)\n",
    "#     print('#######################')\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "#     print(tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))\n",
    "#     print('#######################')\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "862f4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     output = tf.reshape(inputs, [-1, 3, dim//2, dim//2])\n",
    "\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim//2, 5, output, stride=2)\n",
    "#     print('Discriminator output 1: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 1 nonlinear: ', output)\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim,  2 * dim, 5, output, stride=2)\n",
    "#     print('Discriminator output 2: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 2 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 2 nonlinear: ', output)\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.3\", 2 * dim,  4 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     print('Discriminator output 3: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 3 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 3 nonlinear: ', output)\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.4\", 4 * dim,  8 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     print('Discriminator output 4: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 4 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 4 nonlinear: ', output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "#     print('Discriminator output final: ', output, [-1, 4 * 4 * 8 * dim  ])\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "# #     output = lib.ops.conv2d.Conv2D(\n",
    "# #         \"Discriminator.5\", 8 * dim, 16 * dim, 5, output, stride=2\n",
    "# #     )\n",
    "# #     print('Discriminator output 5: ', output)\n",
    "# #     if bn:\n",
    "# #         output = Batchnorm(\"Discriminator.BN5\", [0, 2, 3], output)\n",
    "# #         print('Discriminator output 5 bn: ', output)\n",
    "# #     output = nonlinearity(output)\n",
    "# #     print('Discriminator output 5 nonlinear: ', output)\n",
    "# #     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "# #     print('Discriminator output final: ', output)\n",
    "# #     print('#######################')\n",
    "# ######################\n",
    "#     sourceOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "#     )\n",
    "#     print('Discriminator source output: ', output, 4 * 4 * 8 * dim)\n",
    "#     classOutput = lib.ops.linear.Linear(\n",
    "#         \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "#     )\n",
    "#     print('Discriminator class output: ', output, 4 * 4 * 8 * dim)\n",
    "#     print('#######################')\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "#     print(tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))\n",
    "#     print('#######################')\n",
    "#     return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f57266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANGenerator(\n",
    "    n_samples,\n",
    "    numClasses,\n",
    "    labels,\n",
    "    noise=None,\n",
    "    dim=DIM,\n",
    "    bn=True,\n",
    "    nonlinearity=tf.nn.relu,\n",
    "    condition=None,\n",
    "):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    noise = tf.concat([noise, labels], 1)\n",
    "\n",
    "    output = lib.ops.linear.Linear(\n",
    "        \"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise\n",
    "    )  # probs need to recalculate dimensions\n",
    "    print('Generator output 1: ', output)\n",
    "    output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "    print('Generator output 1 reshape: ', output, output.shape)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "        print('Generator output 1 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 8 * dim * 2 , 4, 4])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl1\",\n",
    "         8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 1 final: ', output)\n",
    "    print('Structure 1: ',  8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "    print('Generator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "        print('Generator output 2 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl2\",\n",
    "         4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 2 final: ', output)\n",
    "    print('Structure 2: ',  4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 4 * dim, 2 * dim * 2, 5, output)\n",
    "    print('Generator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "        print('Generator output 3 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim * 2 , 16, 16])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl3\",\n",
    "         2 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 3 final: ', output)\n",
    "    print('Structure 3: ',  2 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "    print('Generator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "        print('Generator output 4 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim , 32, 32])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl4\",\n",
    "         dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 4 final: ', output)\n",
    "    print('Structure 4: ',  dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, dim , 5, output)\n",
    "#     print('Generator output 5: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN5\", [0, 2, 3], output)\n",
    "#         print('Generator output 5 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond5\", numClasses, 32 * 64 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, dim , 64, 64])\n",
    "#     print('Generator condition 5: ', condition, condition[:, ::2], condition[:, 1::2])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl5\",\n",
    "#         dim//2,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 5 final: ', output)\n",
    "#     print('Structure 5: ',dim//2, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim//2, 3, 5, output)\n",
    "    print('Generator output 5: ', output)\n",
    "    output = tf.tanh(output)\n",
    "    print('Generator output final: ', output)\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61bb69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "    output = tf.reshape(inputs, [-1, 3, dim//2, dim//2])\n",
    "\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "    print('Discriminator output 1: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 1 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim,  2 * dim, 5, output, stride=2)\n",
    "    print('Discriminator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "        print('Discriminator output 2 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 2 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.3\", 2 * dim,  4 * dim, 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "        print('Discriminator output 3 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 3 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\n",
    "        \"Discriminator.4\", 4 * dim,  8 * dim , 5, output, stride=2\n",
    "    )\n",
    "    print('Discriminator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "        print('Discriminator output 4 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 4 nonlinear: ', output)\n",
    "    finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "    print('Discriminator output final: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.5\", 8 * dim, 16 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     print('Discriminator output 5: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN5\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 5 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 5 nonlinear: ', output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "#     print('Discriminator output final: ', output)\n",
    "#     print('#######################')\n",
    "######################\n",
    "    sourceOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "    )\n",
    "    print('Discriminator source output: ', output, 4 * 4 * 8 * dim)\n",
    "    classOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "    )\n",
    "    print('Discriminator class output: ', output, 4 * 4 * 8 * dim)\n",
    "    print('#######################')\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print(tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))\n",
    "    print('#######################')\n",
    "    return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddbf5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomLabels(n_samples, numClasses, condition=None):\n",
    "    labels = np.zeros([BATCH_SIZE, CLASSES], dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        if condition is not None:\n",
    "            labelNum = condition\n",
    "        else:\n",
    "            labelNum = randint(0, numClasses - 1)\n",
    "        labels[i, labelNum] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dafeb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator, Discriminator = GeneratorAndDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9fdf700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started ...\n",
      "real_data:  Tensor(\"Reshape:0\", shape=(84, 49152), dtype=float32, device=/device:GPU:0)\n",
      "real_labels:  Tensor(\"Reshape_1:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "generated_labels:  Tensor(\"Reshape_2:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "sample_labels:  Tensor(\"Reshape_3:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "Generator output 1:  Tensor(\"Generator.Input/BiasAdd:0\", shape=(84, 32768), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_4:0\", shape=(84, 2048, 4, 4), dtype=float32, device=/device:GPU:0) (84, 2048, 4, 4)\n",
      "WARNING:tensorflow:From /home/ec2-user/SageMaker/Masters-thesis/AC-WGAN/tflib/ops/batchnorm.py:51: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3:0\", shape=(84, 2048, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 final:  Tensor(\"mul_1:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Structure 1:  1024 Tensor(\"strided_slice_4:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_5:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_6:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_7:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2/NHWC_to_NCHW:0\", shape=(84, 1024, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_1:0\", shape=(84, 1024, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 final:  Tensor(\"mul_2:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Structure 2:  512 Tensor(\"strided_slice_12:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_13:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_14:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_15:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3/NHWC_to_NCHW:0\", shape=(84, 512, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_2:0\", shape=(84, 512, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 final:  Tensor(\"mul_3:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Structure 3:  256 Tensor(\"strided_slice_20:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_21:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_22:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_23:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4/NHWC_to_NCHW:0\", shape=(84, 256, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_3:0\", shape=(84, 256, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 final:  Tensor(\"mul_4:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Structure 4:  128 Tensor(\"strided_slice_28:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_29:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_30:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_31:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 5:  Tensor(\"Generator.5/NHWC_to_NCHW:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Generator output final:  Tensor(\"Tanh_4:0\", shape=(84, 3, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "fake_data:  Tensor(\"Reshape_9:0\", shape=(21, 49152), dtype=float32, device=/device:GPU:0) 84 2 Tensor(\"Reshape_2:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "fake_labels:  Tensor(\"Cast_1:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1/BiasAdd:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2/BiasAdd:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm/add_1:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_1:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3/BiasAdd:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_1/add_1:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_2:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4/BiasAdd:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_2/add_1:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_3:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_3:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_3:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0) 16384\n",
      "Discriminator class output:  Tensor(\"Maximum_3:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0) 16384\n",
      "#######################\n",
      "Tensor(\"Reshape_18:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_19:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "disc fake:  Tensor(\"Reshape_20:0\", shape=(84,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_21:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_1/BiasAdd:0\", shape=(336, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_4:0\", shape=(336, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_1/BiasAdd:0\", shape=(336, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_3/add_1:0\", shape=(336, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_5:0\", shape=(336, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 3:  Tensor(\"Discriminator.3_1/BiasAdd:0\", shape=(336, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 bn:  Tensor(\"batchnorm_4/add_1:0\", shape=(336, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 3 nonlinear:  Tensor(\"Maximum_6:0\", shape=(336, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 4:  Tensor(\"Discriminator.4_1/BiasAdd:0\", shape=(336, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 bn:  Tensor(\"batchnorm_5/add_1:0\", shape=(336, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 4 nonlinear:  Tensor(\"Maximum_7:0\", shape=(336, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output final:  Tensor(\"Maximum_7:0\", shape=(336, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator source output:  Tensor(\"Maximum_7:0\", shape=(336, 1024, 4, 4), dtype=float32, device=/device:GPU:0) 16384\n",
      "Discriminator class output:  Tensor(\"Maximum_7:0\", shape=(336, 1024, 4, 4), dtype=float32, device=/device:GPU:0) 16384\n",
      "#######################\n",
      "Tensor(\"Reshape_30:0\", shape=(336,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_31:0\", shape=(336, 2), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "disc real:  Tensor(\"Reshape_32:0\", shape=(336,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_33:0\", shape=(336, 2), dtype=float32, device=/device:GPU:0)\n",
      "prediction 1:  Tensor(\"ArgMax:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_21:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 1:  Tensor(\"ArgMax_1:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Cast_1:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "equality 1:  Tensor(\"Equal:0\", shape=(84,), dtype=bool, device=/device:GPU:0)\n",
      "accuracy 1:  Tensor(\"Mean:0\", shape=(), dtype=float32, device=/device:GPU:0)\n",
      "prediction 2:  Tensor(\"ArgMax_2:0\", shape=(336,), dtype=int64, device=/device:GPU:0)\n",
      "disc real class:  Tensor(\"Reshape_33:0\", shape=(336, 2), dtype=float32, device=/device:GPU:0)\n",
      "correct 2:  Tensor(\"ArgMax_3:0\", shape=(84,), dtype=int64, device=/device:GPU:0) Tensor(\"Reshape_1:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 336 and 84 for 'Equal_1' (op: 'Equal') with input shapes: [336], [84].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 336 and 84 for 'Equal_1' (op: 'Equal') with input shapes: [336], [84].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c4d42fd8c9b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'correct 2: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m#             equality = tf.equal(correct_answer, prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mequality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_answer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'equality 2: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mrealAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequality\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mof\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m   \"\"\"\n\u001b[0;32m-> 1306\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[1;32m   3625\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   3626\u001b[0m         \u001b[0;34m\"Equal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincompatible_shape_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3627\u001b[0;31m                  name=name)\n\u001b[0m\u001b[1;32m   3628\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 336 and 84 for 'Equal_1' (op: 'Equal') with input shapes: [336], [84]."
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n",
    "    print('started ...')\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, DIM, DIM])\n",
    "    all_real_label_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    generated_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "    sample_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n",
    "    split_real_label_conv = tf.split(all_real_label_conv, len(DEVICES))\n",
    "    split_generated_labels_conv = tf.split(generated_labels_conv, len(DEVICES))\n",
    "    split_sample_labels_conv = tf.split(sample_labels_conv, len(DEVICES))\n",
    "\n",
    "    gen_costs, disc_costs = [], []\n",
    "\n",
    "    for device_index, (device, real_data_conv, real_label_conv) in enumerate(\n",
    "        zip(DEVICES, split_real_data_conv, split_real_label_conv)\n",
    "    ):\n",
    "        with tf.device(device):\n",
    "\n",
    "            real_data = tf.reshape(\n",
    "                2 * ((tf.cast(real_data_conv, tf.float32) / 255.0) - 0.5),\n",
    "                [BATCH_SIZE // len(DEVICES), OUTPUT_DIM],\n",
    "            )\n",
    "            print('real_data: ', real_data)\n",
    "            real_labels = tf.reshape(\n",
    "                real_label_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('real_labels: ', real_labels)\n",
    "            generated_labels = tf.reshape(\n",
    "                split_generated_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('generated_labels: ', generated_labels)\n",
    "            sample_labels = tf.reshape(\n",
    "                split_sample_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('sample_labels: ', sample_labels)\n",
    "            fake_data, fake_labels = Generator(\n",
    "                BATCH_SIZE // len(DEVICES), CLASSES, generated_labels\n",
    "            )\n",
    "#             print(real_data,real_labels,generated_labels,sample_labels,fake_data, fake_labels)\n",
    "            print('fake_data: ', fake_data,BATCH_SIZE // len(DEVICES), CLASSES, generated_labels)\n",
    "            print('fake_labels: ', fake_labels)\n",
    "            # set up discrimnator results\n",
    "\n",
    "            disc_fake, disc_fake_class = Discriminator(fake_data, CLASSES)\n",
    "            print('disc fake: ', disc_fake, disc_fake_class)\n",
    "            disc_real, disc_real_class = Discriminator(real_data, CLASSES)\n",
    "            print('disc real: ', disc_real, disc_real_class)\n",
    "            prediction = tf.argmax(disc_fake_class, 1)\n",
    "            print('prediction 1: ', prediction, disc_fake_class)\n",
    "            correct_answer = tf.argmax(fake_labels, 1)\n",
    "            print('correct 1: ', correct_answer, fake_labels)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 1: ', equality)\n",
    "            genAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            print('accuracy 1: ', genAccuracy)\n",
    "            \n",
    "            prediction = tf.argmax(disc_real_class, 1)\n",
    "            print('prediction 2: ', prediction)\n",
    "            print('disc real class: ', disc_real_class)\n",
    "            correct_answer = tf.argmax(real_labels, 1)\n",
    "            print('correct 2: ', correct_answer, real_labels)\n",
    "#             equality = tf.equal(correct_answer, prediction)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 2: ', equality)\n",
    "            realAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            print('accuracy 2: ', equality)\n",
    "            gen_cost = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            gen_cost_test = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost_test = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            generated_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_fake_class, labels=fake_labels\n",
    "                )\n",
    "            )\n",
    "\n",
    "            real_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_real_class, labels=real_labels\n",
    "                )\n",
    "            )\n",
    "            gen_cost += generated_class_cost\n",
    "            disc_cost += real_class_cost\n",
    "\n",
    "            alpha = tf.random_uniform(\n",
    "                shape=[BATCH_SIZE // len(DEVICES), 1], minval=0.0, maxval=1.0\n",
    "            )\n",
    "            differences = fake_data - real_data\n",
    "            interpolates = real_data + (alpha * differences)\n",
    "            gradients = tf.gradients(\n",
    "                Discriminator(interpolates, CLASSES)[0], [interpolates]\n",
    "            )[0]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes - 1.0) ** 2)\n",
    "            disc_cost += LAMBDA * gradient_penalty\n",
    "\n",
    "            real_class_cost_gradient = real_class_cost * 50 + LAMBDA * gradient_penalty\n",
    "\n",
    "            gen_costs.append(gen_cost)\n",
    "            disc_costs.append(disc_cost)\n",
    "\n",
    "    gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "    disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
    "\n",
    "    gen_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        gen_cost,\n",
    "        var_list=lib.params_with_name(\"Generator\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    disc_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        disc_cost,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    class_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        real_class_cost_gradient,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    # For generating samples\n",
    "\n",
    "    fixed_noise = tf.constant(\n",
    "        np.random.normal(size=(BATCH_SIZE, 128)).astype(\"float32\")\n",
    "    )\n",
    "    all_fixed_noise_samples = []\n",
    "    for device_index, device in enumerate(DEVICES):\n",
    "        n_samples = BATCH_SIZE // len(DEVICES)\n",
    "        all_fixed_noise_samples.append(\n",
    "            Generator(\n",
    "                n_samples,\n",
    "                CLASSES,\n",
    "                sample_labels,\n",
    "                noise=fixed_noise[\n",
    "                    device_index * n_samples : (device_index + 1) * n_samples\n",
    "                ],\n",
    "            )[0]\n",
    "        )\n",
    "        if tf.__version__.startswith(\"1.\"):\n",
    "            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n",
    "        else:\n",
    "            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
    "\n",
    "    def generate_image(iteration):\n",
    "        # this might be where we add the conditionality\n",
    "        for i in range(CLASSES):\n",
    "            curLabel = genRandomLabels(BATCH_SIZE, CLASSES, condition=i)\n",
    "            samples = session.run(\n",
    "                all_fixed_noise_samples, feed_dict={sample_labels: curLabel}\n",
    "            )\n",
    "            samples = ((samples + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "            lib.save_images.save_images(\n",
    "                samples.reshape((BATCH_SIZE, 3, DIM, DIM)),\n",
    "                \"generated/samples_{}_{}.png\".format(str(i), iteration),\n",
    "            )\n",
    "\n",
    "    # Dataset iterator\n",
    "#     train_gen, dev_gen = lib.wikiart_genre.load(BATCH_SIZE)\n",
    "    train_gen, dev_gen = load(BATCH_SIZE)\n",
    "\n",
    "    def softmax_cross_entropy(logit, y):\n",
    "        return -tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y)\n",
    "        )\n",
    "\n",
    "    def inf_train_gen():\n",
    "        while True:\n",
    "            for (images, labels) in train_gen():\n",
    "                yield images, labels\n",
    "\n",
    "    _sample_labels = genRandomLabels(BATCH_SIZE, CLASSES)\n",
    "    # Save a batch of ground-truth samples\n",
    "    _x, _y = next(train_gen())\n",
    "    _x_r = session.run(real_data, feed_dict={all_real_data_conv: _x})\n",
    "    _x_r = ((_x_r + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "    lib.save_images.save_images(\n",
    "        _x_r.reshape((BATCH_SIZE, 3, DIM, DIM)), \"generated/samples_groundtruth.png\"\n",
    "    )\n",
    "\n",
    "    session.run(\n",
    "        tf.initialize_all_variables(),\n",
    "        feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "    )\n",
    "    gen = train_gen()\n",
    "\n",
    "    for iterp in range(PREITERATIONS):\n",
    "        _data, _labels = next(gen)\n",
    "        _, accuracy = session.run(\n",
    "            [disc_train_op, realAccuracy],\n",
    "            feed_dict={\n",
    "                all_real_data_conv: _data,\n",
    "                all_real_label_conv: _labels,\n",
    "                generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "            },\n",
    "        )\n",
    "        if iterp % 100 == 99:\n",
    "            print(\"pretraining accuracy: \" + str(accuracy))\n",
    "\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(\n",
    "                gen_train_op,\n",
    "                feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "            )\n",
    "        # Train critic\n",
    "        disc_iters = CRITIC_ITERS\n",
    "        for i in range(disc_iters):\n",
    "            _data, _labels = next(gen)\n",
    "            (\n",
    "                _disc_cost,\n",
    "                _disc_cost_test,\n",
    "                class_cost_test,\n",
    "                gen_class_cost,\n",
    "                _gen_cost_test,\n",
    "                _genAccuracy,\n",
    "                _realAccuracy,\n",
    "                _,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                    disc_train_op,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: _data,\n",
    "                    all_real_label_conv: _labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "\n",
    "        lib.plot.plot(\"train disc cost\", _disc_cost)\n",
    "        lib.plot.plot(\"time\", time.time() - start_time)\n",
    "        lib.plot.plot(\"wgan train disc cost\", _disc_cost_test)\n",
    "        lib.plot.plot(\"train class cost\", class_cost_test)\n",
    "        lib.plot.plot(\"generated class cost\", gen_class_cost)\n",
    "        lib.plot.plot(\"gen cost cost\", _gen_cost_test)\n",
    "        lib.plot.plot(\"gen accuracy\", _genAccuracy)\n",
    "        lib.plot.plot(\"real accuracy\", _realAccuracy)\n",
    "\n",
    "        if (iteration % 100 == 99 and iteration < 1000) or iteration % 1000 == 999:\n",
    "            t = time.time()\n",
    "            dev_disc_costs = []\n",
    "            images, labels = next(dev_gen())\n",
    "            (\n",
    "                _dev_disc_cost,\n",
    "                _dev_disc_cost_test,\n",
    "                _class_cost_test,\n",
    "                _gen_class_cost,\n",
    "                _dev_gen_cost_test,\n",
    "                _dev_genAccuracy,\n",
    "                _dev_realAccuracy,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: images,\n",
    "                    all_real_label_conv: labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot(\"dev disc cost\", np.mean(dev_disc_costs))\n",
    "            lib.plot.plot(\"wgan dev disc cost\", _dev_disc_cost_test)\n",
    "            lib.plot.plot(\"dev class cost\", _class_cost_test)\n",
    "            lib.plot.plot(\"dev generated class cost\", _gen_class_cost)\n",
    "            lib.plot.plot(\"dev gen  cost\", _dev_gen_cost_test)\n",
    "            lib.plot.plot(\"dev gen accuracy\", _dev_genAccuracy)\n",
    "            lib.plot.plot(\"dev real accuracy\", _dev_realAccuracy)\n",
    "\n",
    "        if iteration % 100 == 999:\n",
    "            generate_image(iteration)\n",
    "            # Can add generate_good_images method in here if desired\n",
    "\n",
    "        if (iteration < 10) or (iteration % 100 == 99):\n",
    "            lib.plot.flush()\n",
    "\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef863e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19e7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7638bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312c97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
