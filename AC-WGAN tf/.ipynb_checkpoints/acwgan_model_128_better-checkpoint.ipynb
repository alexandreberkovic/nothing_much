{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bd64371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions '"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "65e13ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "00ebbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "27c7a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimension of images you want to be passed in to the network\n",
    "DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "70d6ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your own path to images\n",
    "# src_img_path  = Path('/home/ec2-user/SageMaker/genre-128')\n",
    "src_img_path  = Path('/home/ec2-user/SageMaker/portrait_landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7ce87e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(src_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a7d8d6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14971"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(src_img_path,'1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "770d5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary should be updated to hold the absolute number of images associated with each genre used during training\n",
    "styles = {\n",
    "    \"portraits\": 14981,\n",
    "    \"landscapes\": 14971\n",
    "}\n",
    "\n",
    "styleNum = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 1\n",
    "}\n",
    "    \n",
    "curPos = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "246c9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNums = {}\n",
    "trainNums = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "130b161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set of images made up of 1/20 of the images (per genre)\n",
    "for k, v in styles.items():\n",
    "    # put a twentieth of paintings in here\n",
    "    nums = range(v)\n",
    "    random.shuffle(list(nums))\n",
    "    testNums[k] = nums[0 : v // 20]\n",
    "    trainNums[k] = nums[v // 20 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "91b00ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'portraits': range(749, 14981), 'landscapes': range(748, 14971)}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5b86456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_gen(gen):\n",
    "    while True:\n",
    "        for (images, labels) in gen():\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "496abbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(files, batch_size, n_classes): # add genre parameter\n",
    "    if batch_size % n_classes != 0:\n",
    "        raise ValueError(\n",
    "            \"Batch size {} must be divisible by num classes {}\".format(batch_size, n_classes)\n",
    "        )\n",
    "\n",
    "    class_batch = batch_size // n_classes\n",
    "\n",
    "    generators = []\n",
    "\n",
    "    def get_epoch():\n",
    "\n",
    "        while True:\n",
    "\n",
    "            images = np.zeros((batch_size, 3, DIM, DIM), dtype=\"int32\")\n",
    "            labels = np.zeros((batch_size, n_classes))\n",
    "            n = 0\n",
    "            for style in styles:\n",
    "#             for style in genre:\n",
    "                styleLabel = styleNum[style]\n",
    "                curr = curPos[style]\n",
    "                for _ in range(class_batch):\n",
    "                    if curr == styles[style]:\n",
    "                        curr = 0\n",
    "                        random.shuffle(list(files[style]))\n",
    "                    img_path = str(Path(src_img_path, str(styleLabel), str(curr) + \".png\"))\n",
    "                    image = Image.open(img_path).convert(mode=\"RGB\")\n",
    "                    image = np.asarray(image)\n",
    "\n",
    "                    images[n % batch_size] = image.transpose(2, 0, 1)\n",
    "                    labels[n % batch_size, int(styleLabel)] = 1\n",
    "                    n += 1\n",
    "                    curr += 1\n",
    "                curPos[style] = curr\n",
    "\n",
    "            # randomize things but keep relationship between a conditioning vector and its associated image\n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.shuffle(images)\n",
    "            np.random.set_state(rng_state)\n",
    "            np.random.shuffle(labels)\n",
    "            yield (images, labels)\n",
    "\n",
    "    return get_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c647bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size):\n",
    "    return (\n",
    "        make_generator(trainNums, batch_size, len(styles)),\n",
    "        make_generator(testNums, batch_size, len(styles)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "50f065b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "# import tflib.wikiart_genre\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "24f4a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "665ed414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3f3acd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e58ed0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bafa11f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 84\n",
      "\tCLASSES: 2\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDEVICES: ['/gpu:0']\n",
      "\tDIM: 128\n",
      "\tDIM_D_16: 512\n",
      "\tDIM_D_32: 256\n",
      "\tDIM_D_4: 1024\n",
      "\tDIM_D_64: 128\n",
      "\tDIM_D_8: 1024\n",
      "\tDIM_G_16: 256\n",
      "\tDIM_G_32: 128\n",
      "\tDIM_G_4: 512\n",
      "\tDIM_G_64: 64\n",
      "\tDIM_G_8: 512\n",
      "\tITERS: 200000\n",
      "\tLAMBDA: 10\n",
      "\tMODE: acwgan\n",
      "\tN_GPUS: 1\n",
      "\tOUTPUT_DIM: 49152\n",
      "\tPREITERATIONS: 2000\n"
     ]
    }
   ],
   "source": [
    "MODE = \"acwgan\"  # dcgan, wgan, wgan-gp, lsgan\n",
    "genre = ['portraits','landscapes']\n",
    "DIM = 128  # Model dimensionality\n",
    "CRITIC_ITERS = 5  # How many iterations to train the critic for, increase it to 50 later\n",
    "N_GPUS = 1  # Number of GPUs\n",
    "BATCH_SIZE = 84  # Batch size. Must be a multiple of CLASSES and N_GPUS\n",
    "ITERS = 200000  # How many iterations to train for\n",
    "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = DIM * DIM * 3  # Number of pixels in each image\n",
    "CLASSES = len(genre)  # Number of classes, for genres probably 14\n",
    "PREITERATIONS = 2000  # Number of preiteration training cycles to run\n",
    "lib.print_model_settings(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c18749b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that directory exists where ground truth and plots will be saved to.\n",
    "Path('generated').mkdir(parents=True, exist_ok=True)\n",
    "Path('models').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c0c27853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratorAndDiscriminator():\n",
    "    return kACGANGenerator, kACGANDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fae709e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [\"/gpu:{}\".format(i) for i in range(N_GPUS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e5b874c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha * x, x)\n",
    "\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "\n",
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return LeakyReLU(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "73330311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batchnorm(name, axes, inputs):\n",
    "\n",
    "    if (\"Discriminator\" in name) and (MODE == \"wgan-gp\" or MODE == \"acwgan\"):\n",
    "        if axes != [0, 2, 3]:\n",
    "            raise Exception(\"Layernorm over non-standard axes is unsupported\")\n",
    "        return lib.ops.layernorm.Layernorm(name, [1, 2, 3], inputs)\n",
    "    else:\n",
    "        return lib.ops.batchnorm.Batchnorm(name, axes, inputs, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "14c391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixcnn_gated_nonlinearity(name, output_dim, a, b, c=None, d=None):\n",
    "    if c is not None and d is not None:\n",
    "        a = a + c\n",
    "        b = b + d\n",
    "    result = tf.sigmoid(a) * tf.tanh(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "996cb063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubpixelConv2D(*args, **kwargs):\n",
    "    kwargs[\"output_dim\"] = 4 * kwargs[\"output_dim\"]\n",
    "    output = lib.ops.conv2d.Conv2D(*args, **kwargs)\n",
    "    output = tf.transpose(output, [0, 2, 3, 1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0, 3, 1, 2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d097b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(\n",
    "    name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True\n",
    "):\n",
    "    \"\"\"\n",
    "    resample: None, 'down', or 'up'\n",
    "    \"\"\"\n",
    "    if resample == \"down\":\n",
    "        conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "            stride=2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == \"up\":\n",
    "        conv_shortcut = SubpixelConv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.deconv2d.Deconv2D,\n",
    "            input_dim=input_dim // 2,\n",
    "            output_dim=output_dim // 2,\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=output_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "    elif resample == None:\n",
    "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
    "        conv_1 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim // 2\n",
    "        )\n",
    "        conv_1b = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim // 2\n",
    "        )\n",
    "        conv_2 = functools.partial(\n",
    "            lib.ops.conv2d.Conv2D, input_dim=input_dim // 2, output_dim=output_dim\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"invalid resample value\")\n",
    "\n",
    "    if output_dim == input_dim and resample == None:\n",
    "        shortcut = inputs  # Identity skip-connection\n",
    "    else:\n",
    "        shortcut = conv_shortcut(\n",
    "            name + \".Shortcut\",\n",
    "            input_dim=input_dim,\n",
    "            output_dim=output_dim,\n",
    "            filter_size=1,\n",
    "            he_init=False,\n",
    "            biases=True,\n",
    "            inputs=inputs,\n",
    "        )\n",
    "\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1(\n",
    "        name + \".Conv1\", filter_size=1, inputs=output, he_init=he_init, weightnorm=False\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1b(\n",
    "        name + \".Conv1B\",\n",
    "        filter_size=filter_size,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "    )\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_2(\n",
    "        name + \".Conv2\",\n",
    "        filter_size=1,\n",
    "        inputs=output,\n",
    "        he_init=he_init,\n",
    "        weightnorm=False,\n",
    "        biases=False,\n",
    "    )\n",
    "    output = Batchnorm(name + \".BN\", [0, 2, 3], output)\n",
    "\n",
    "    return shortcut + (0.3 * output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c0ad5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kACGANGenerator(\n",
    "#     n_samples,\n",
    "#     numClasses,\n",
    "#     labels,\n",
    "#     noise=None,\n",
    "#     dim=DIM,\n",
    "#     bn=True,\n",
    "#     nonlinearity=tf.nn.relu,\n",
    "#     condition=None,\n",
    "# ):\n",
    "#     lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "#     lib.ops.linear.set_weights_stdev(0.02)\n",
    "#     if noise is None:\n",
    "#         noise = tf.random_normal([n_samples, 128])\n",
    "#         print('noise: ', noise)\n",
    "\n",
    "#     labels = tf.cast(labels, tf.float32)\n",
    "#     print('labels: ', labels)\n",
    "#     noise = tf.concat([noise, labels], 1)\n",
    "#     print('noise 2: ', noise)\n",
    "#     output = lib.ops.linear.Linear(\n",
    "#         \"Generator.Input\", 128 + numClasses, 8 * 4 * 4 * dim * 2, noise\n",
    "#     )  # probs need to recalculate dimensions\n",
    "#     print('Generator output 1: ', output)\n",
    "#     output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "# #     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "#     print('Generator output 1 reshape: ', output, output.shape)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "#         print('Generator output 1 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, 8 * dim * 2 , 4, 4])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl1\",\n",
    "#          8 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 1 final: ', output)\n",
    "#     print('Structure 1: ',  8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "# #######################\n",
    "# #     dim = dim//2\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "#     print('Generator output 2: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "#         print('Generator output 2 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "#     )\n",
    "#     print('Linear condition 1: ',condition)\n",
    "#     condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "#     print('Linear condition reshape 1: ',condition)\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl2\",\n",
    "#          4 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 2 final: ', output)\n",
    "#     print('Structure 2: ',  4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "#     print('Generator output 3: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "#         print('Generator output 3 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2, labels\n",
    "#     )\n",
    "#     print('Linear condition 2: ',condition)\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim * 2 , 16, 16])\n",
    "#     print('Linear condition reshape 2: ',condition)\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl3\",\n",
    "#          2 * dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 3 final: ', output)\n",
    "#     print('Structure 3: ',  2 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 2 * dim, dim * 2, 5, output)\n",
    "#     print('Generator output 4: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "#         print('Generator output 4 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond4\", numClasses, 32 * 32 * dim * 2, labels\n",
    "#     )\n",
    "#     print('Linear condition 3: ',condition)\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim , 32, 32])\n",
    "#     print('Linear condition reshape3: ',condition)\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl4\",\n",
    "#          dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 4 final: ', output)\n",
    "#     print('Structure 4: ',  dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "# #######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, dim , 5, output)\n",
    "#     print('Generator output 5: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN5\", [0, 2, 3], output)\n",
    "#         print('Generator output 5 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond5\", numClasses, 32 * 64 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, dim , 64, 64])\n",
    "#     print('Generator condition 5: ', condition, condition[:, ::2], condition[:, 1::2])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl5\",\n",
    "#         dim//2,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 5 final: ', output)\n",
    "#     print('Structure 5: ',dim//2, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "# ######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.6\", dim, 3, 5, output)\n",
    "#     print('Generator output 6: ', output)\n",
    "#     output = tf.tanh(output)\n",
    "#     print('Generator output final: ', output)\n",
    "#     lib.ops.conv2d.unset_weights_stdev()\n",
    "#     lib.ops.deconv2d.unset_weights_stdev()\n",
    "#     lib.ops.linear.unset_weights_stdev()\n",
    "#     print('#######################')\n",
    "\n",
    "#     return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "572ca332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANGenerator(\n",
    "    n_samples,\n",
    "    numClasses,\n",
    "    labels,\n",
    "    noise=None,\n",
    "    dim=DIM,\n",
    "    bn=True,\n",
    "    nonlinearity=tf.nn.relu,\n",
    "    condition=None,\n",
    "):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "        print('noise: ', noise)\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    print('labels: ', labels)\n",
    "    noise = tf.concat([noise, labels], 1)\n",
    "    print('noise 2: ', noise)\n",
    "    output = lib.ops.linear.Linear(\n",
    "        \"Generator.Input\", 128 + numClasses, 8 * 4 * dim * 4 *2 , noise\n",
    "    )  # probs need to recalculate dimensions\n",
    "    print('Generator output 1: ', output)\n",
    "    output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "    print('Generator output 1 reshape: ', output, output.shape)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "        print('Generator output 1 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 8 * dim * 2 , 4, 4])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl1\",\n",
    "         8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 1 final: ', output)\n",
    "    print('Structure 1: ',  8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "#     dim = dim//2\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "    print('Generator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "        print('Generator output 2 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "    )\n",
    "    print('Linear condition 1: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "    print('Linear condition reshape 1: ',condition)\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl2\",\n",
    "         8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 2 final: ', output)\n",
    "    print('Structure 2: ',  8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 8 * dim//2, 4 * dim * 2//2, 5, output)\n",
    "    print('Generator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "        print('Generator output 3 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 4 * 8 * 8 * dim * 4, labels\n",
    "    )\n",
    "    print('Linear condition 2: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2//2, 16, 16])\n",
    "    print('Linear condition reshape 2: ',condition)\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl3\",\n",
    "         4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 3 final: ', output)\n",
    "    print('Structure 3: ',  4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 8 * dim//2, 4 * dim * 2//2, 5, output)\n",
    "    print('Generator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "        print('Generator output 3 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 4 * 8 * 8 * dim * 4 *2, labels\n",
    "    )\n",
    "    print('Linear condition 2: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2//4, 32, 32])\n",
    "    print('Linear condition reshape 2: ',condition)\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl3\",\n",
    "         4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2]\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 3 final: ', output)\n",
    "    print('Structure 3: ',  4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "\n",
    "    \n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 4 * dim//2, 2 * dim * 2//2, 5, output)\n",
    "    print('Generator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "        print('Generator output 4 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 2 * 16 * 16 * dim * 2 , labels\n",
    "    )\n",
    "    print('Linear condition 3: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim * 2//4 , 64, 64])\n",
    "    print('Linear condition reshape 3: ',condition)\n",
    "    print('Structure 4: ',  2 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl4\",\n",
    "         2 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2]\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 4 final: ', output)\n",
    "    \n",
    "    print('#######################')\n",
    "#######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", 2 * dim//2, dim * 2//2, 5, output)\n",
    "#     print('Generator output 5: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN5\", [0, 2, 3], output)\n",
    "#         print('Generator output 5 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond5\", numClasses, 32 * 32 * dim * 2, labels\n",
    "#     )\n",
    "#     print('Linear condition 4: ',condition)\n",
    "#     condition = tf.reshape(condition, [-1, 2 * dim , 64, 64])\n",
    "#     print('Linear condition reshape 4: ',condition)\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl5\",\n",
    "#          dim,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 5 final: ', output)\n",
    "#     print('Structure 5: ',  dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "#######################\n",
    "#     output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", dim, dim , 5, output)\n",
    "#     print('Generator output 5: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Generator.BN5\", [0, 2, 3], output)\n",
    "#         print('Generator output 5 bn: ', output)\n",
    "#     condition = lib.ops.linear.Linear(\n",
    "#         \"Generator.cond5\", numClasses, 32 * 64 * dim * 2, labels\n",
    "#     )\n",
    "#     condition = tf.reshape(condition, [-1, dim , 64, 64])\n",
    "#     print('Generator condition 5: ', condition, condition[:, ::2], condition[:, 1::2])\n",
    "#     output = pixcnn_gated_nonlinearity(\n",
    "#         \"Generator.nl5\",\n",
    "#         dim//2,\n",
    "#         output[:, ::2],\n",
    "#         output[:, 1::2],\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "#     )\n",
    "#     print('Generator output 5 final: ', output)\n",
    "#     print('Structure 5: ',dim//2, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "#     print('#######################')\n",
    "######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.6\", dim, 3, 5, output)\n",
    "    print('Generator output 6: ', output)\n",
    "    output = tf.tanh(output)\n",
    "    print('Generator output final: ', output)\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9efca6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANGenerator(\n",
    "    n_samples,\n",
    "    numClasses,\n",
    "    labels,\n",
    "    noise=None,\n",
    "    dim=DIM,\n",
    "    bn=True,\n",
    "    nonlinearity=tf.nn.relu,\n",
    "    condition=None,\n",
    "):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "        print('noise: ', noise)\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    print('labels: ', labels)\n",
    "    noise = tf.concat([noise, labels], 1)\n",
    "    print('noise 2: ', noise)\n",
    "    output = lib.ops.linear.Linear(\n",
    "        \"Generator.Input\", 128 + numClasses, 8 * 4 * dim * 4 *2 , noise\n",
    "    )  # probs need to recalculate dimensions\n",
    "    print('Generator output 1: ', output)\n",
    "    output = tf.reshape(output, [-1, 8 * dim * 2, 4, 4])\n",
    "#     output = tf.reshape(output, [-1, dim , 4, 4])\n",
    "    print('Generator output 1 reshape: ', output, output.shape)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN1\", [0, 2, 3], output)\n",
    "        print('Generator output 1 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond1\", numClasses, 8 * 4 * 4 * dim * 2, labels, biases=False\n",
    "    )\n",
    "    condition = tf.reshape(condition, [-1, 8 * dim * 2 , 4, 4])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl1\",\n",
    "         8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 1 final: ', output)\n",
    "    print('Structure 1: ',  8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "#     dim = dim//2\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.2\", 8 * dim, 4 * dim * 2, 5, output)\n",
    "    print('Generator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN2\", [0, 2, 3], output)\n",
    "        print('Generator output 2 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond2\", numClasses, 4 * 8 * 8 * dim * 2, labels\n",
    "    )\n",
    "    print('Linear condition 1: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2, 8, 8])\n",
    "    print('Linear condition reshape 1: ',condition)\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl2\",\n",
    "         8 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 2 final: ', output)\n",
    "    print('Structure 2: ',  8 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.3\", 8 * dim//2, 4 * dim * 2//2, 5, output)\n",
    "    print('Generator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN3\", [0, 2, 3], output)\n",
    "        print('Generator output 3 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond3\", numClasses, 4 * 8 * 8 * dim * 4, labels\n",
    "    )\n",
    "    print('Linear condition 2: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2//2, 16, 16])\n",
    "    print('Linear condition reshape 2: ',condition)\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl3\",\n",
    "         4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 3 final: ', output)\n",
    "    print('Structure 3: ',  4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "#######################\n",
    "\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.4\", 8 * dim//4, 4 * dim * 2//4, 5, output)\n",
    "    print('Generator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN4\", [0, 2, 3], output)\n",
    "        print('Generator output 4 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond4\", numClasses, 4 * 8 * 8 * dim * 4 *2, labels\n",
    "    )\n",
    "    print('Linear condition 3: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 4 * dim * 2//4, 32, 32])\n",
    "    print('Linear condition reshape 3: ',condition)\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl4\",\n",
    "         4 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2],\n",
    "        condition[:, ::2],\n",
    "        condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 4 final: ', output)\n",
    "    print('Structure 4: ',  4 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    print('#######################')\n",
    "\n",
    "    \n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.5\", 8 * dim//4, 4 * dim * 2//4, 5, output)\n",
    "    print('Generator output 5: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Generator.BN5\", [0, 2, 3], output)\n",
    "        print('Generator output 5 bn: ', output)\n",
    "    condition = lib.ops.linear.Linear(\n",
    "        \"Generator.cond5\", numClasses, 8 * 16 * 16 * dim * 2 , labels\n",
    "    )\n",
    "    print('Linear condition 4: ',condition)\n",
    "    condition = tf.reshape(condition, [-1, 2 * dim * 2//4 , 64, 64])\n",
    "    print('Linear condition reshape 4: ',condition)\n",
    "    print('Structure 5: ',  2 * dim, output[:, ::2], output[:, 1::2], condition[:, ::2], condition[:, 1::2])\n",
    "    output = pixcnn_gated_nonlinearity(\n",
    "        \"Generator.nl5\",\n",
    "         2 * dim,\n",
    "        output[:, ::2],\n",
    "        output[:, 1::2]\n",
    "#         condition[:, ::2],\n",
    "#         condition[:, 1::2],\n",
    "    )\n",
    "    print('Generator output 5 final: ', output)\n",
    "    \n",
    "    print('#######################')\n",
    "#######################\n",
    "\n",
    "######################\n",
    "    output = lib.ops.deconv2d.Deconv2D(\"Generator.6\", dim, 3, 5, output)\n",
    "    print('Generator output 6: ', output)\n",
    "    output = tf.tanh(output)\n",
    "    print('Generator output final: ', output)\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e099c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_G_64  = 64\n",
    "DIM_G_32  = 128\n",
    "DIM_G_16  = 256\n",
    "DIM_G_8   = 512\n",
    "DIM_G_4   = 512\n",
    "\n",
    "\n",
    "DIM_D_64  = 128\n",
    "DIM_D_32  = 256\n",
    "DIM_D_16  = 512\n",
    "DIM_D_8   = 1024\n",
    "DIM_D_4   = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4663fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "    output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "    labels = 2\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.1\", 3, dim, 5, output, stride=2)\n",
    "    print('Discriminator output 1: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 1 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim,  2 * dim, 5, output, stride=2)\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.2\", dim//2,   dim, 5, output, stride=2)\n",
    "    print('Discriminator output 2: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN2\", [0, 2, 3], output)\n",
    "        print('Discriminator output 2 bn: ', output)   \n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 2 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.3\", 2 * dim,  4 * dim, 5, output, stride=2)\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.3\", dim,  2 * dim, 5, output, stride=2)\n",
    "    print('Discriminator output 3: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN3\", [0, 2, 3], output)\n",
    "        print('Discriminator output 3 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 3 nonlinear: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "    output = lib.ops.conv2d.Conv2D(\"Discriminator.4\", 4 * dim,  4 * dim , 5, output, stride=2)\n",
    "#     output = lib.ops.conv2d.Conv2D(\"Discriminator.4\",  dim,  2* dim , 5, output, stride=2)\n",
    "    print('Discriminator output 4: ', output)\n",
    "    if bn:\n",
    "        output = Batchnorm(\"Discriminator.BN4\", [0, 2, 3], output)\n",
    "        print('Discriminator output 4 bn: ', output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 4 nonlinear: ', output)\n",
    "    finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "    print('Discriminator output final: ', output)\n",
    "    print('#######################')\n",
    "######################\n",
    "#     output = lib.ops.conv2d.Conv2D(\n",
    "#         \"Discriminator.5\", 8 * dim, 16 * dim, 5, output, stride=2\n",
    "#     )\n",
    "#     print('Discriminator output 5: ', output)\n",
    "#     if bn:\n",
    "#         output = Batchnorm(\"Discriminator.BN5\", [0, 2, 3], output)\n",
    "#         print('Discriminator output 5 bn: ', output)\n",
    "#     output = nonlinearity(output)\n",
    "#     print('Discriminator output 5 nonlinear: ', output)\n",
    "#     finalLayer = tf.reshape(output, [-1, 4 * 4 * 8 * dim])\n",
    "#     print('Discriminator output final: ', output)\n",
    "#     print('#######################')\n",
    "######################\n",
    "    sourceOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.sourceOutput\", 4 * 4 * 8 * dim, 1, finalLayer\n",
    "    )\n",
    "    print('Discriminator source output: ', output, 4 * 4 * 8 * dim)\n",
    "    classOutput = lib.ops.linear.Linear(\n",
    "        \"Discriminator.classOutput\", 4 * 4 * 8 * dim, numClasses, finalLayer\n",
    "    )\n",
    "    print('Discriminator class output: ', output, 4 * 4 * 8 * dim)\n",
    "    print('#######################')\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print(tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))\n",
    "    print('#######################')\n",
    "    return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "db65660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomLabels(n_samples, numClasses, condition=None):\n",
    "    labels = np.zeros([BATCH_SIZE, CLASSES], dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        if condition is not None:\n",
    "            labelNum = condition\n",
    "        else:\n",
    "            labelNum = randint(0, numClasses - 1)\n",
    "        labels[i, labelNum] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "39847765",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator, Discriminator = GeneratorAndDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a1597d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started ...\n",
      "real_data:  Tensor(\"Reshape_485:0\", shape=(84, 49152), dtype=float32, device=/device:GPU:0)\n",
      "real_labels:  Tensor(\"Reshape_486:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "generated_labels:  Tensor(\"Reshape_487:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "sample_labels:  Tensor(\"Reshape_488:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "noise:  Tensor(\"random_normal_36:0\", shape=(84, 128), dtype=float32, device=/device:GPU:0)\n",
      "labels:  Tensor(\"Cast_73:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "noise 2:  Tensor(\"concat_36:0\", shape=(84, 130), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1:  Tensor(\"Generator.Input_36/BiasAdd:0\", shape=(84, 32768), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 reshape:  Tensor(\"Reshape_489:0\", shape=(84, 2048, 4, 4), dtype=float32, device=/device:GPU:0) (84, 2048, 4, 4)\n",
      "Generator output 1 bn:  Tensor(\"FusedBatchNormV3_173:0\", shape=(84, 2048, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 1 final:  Tensor(\"mul_270:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "Structure 1:  1024 Tensor(\"strided_slice_1298:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1299:0\", shape=(84, 512, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1300:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1301:0\", shape=(84, 1024, 4, 4), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 2:  Tensor(\"Generator.2_36/NHWC_to_NCHW:0\", shape=(84, 1024, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 bn:  Tensor(\"FusedBatchNormV3_174:0\", shape=(84, 1024, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition 1:  Tensor(\"Generator.cond2_36/BiasAdd:0\", shape=(84, 65536), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition reshape 1:  Tensor(\"Reshape_491:0\", shape=(84, 1024, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 2 final:  Tensor(\"mul_271:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "Structure 2:  1024 Tensor(\"strided_slice_1306:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1307:0\", shape=(84, 256, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1308:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1309:0\", shape=(84, 512, 8, 8), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 3:  Tensor(\"Generator.3_53/NHWC_to_NCHW:0\", shape=(84, 512, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 bn:  Tensor(\"FusedBatchNormV3_175:0\", shape=(84, 512, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition 2:  Tensor(\"Generator.cond3_70/BiasAdd:0\", shape=(84, 131072), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition reshape 2:  Tensor(\"Reshape_492:0\", shape=(84, 512, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 3 final:  Tensor(\"mul_272:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "Structure 3:  512 Tensor(\"strided_slice_1314:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1315:0\", shape=(84, 128, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1316:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1317:0\", shape=(84, 256, 16, 16), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 4:  Tensor(\"Generator.4_36/NHWC_to_NCHW:0\", shape=(84, 256, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 bn:  Tensor(\"FusedBatchNormV3_176:0\", shape=(84, 256, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition 3:  Tensor(\"Generator.cond4_17/BiasAdd:0\", shape=(84, 262144), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition reshape 3:  Tensor(\"Reshape_493:0\", shape=(84, 256, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 4 final:  Tensor(\"mul_273:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Structure 4:  512 Tensor(\"strided_slice_1322:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1323:0\", shape=(84, 64, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1324:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1325:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 5:  Tensor(\"Generator.5_17/NHWC_to_NCHW:0\", shape=(84, 256, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 5 bn:  Tensor(\"FusedBatchNormV3_177:0\", shape=(84, 256, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition 4:  Tensor(\"Generator.cond5_14/BiasAdd:0\", shape=(84, 131072), dtype=float32, device=/device:GPU:0)\n",
      "Linear condition reshape 4:  Tensor(\"Reshape_494:0\", shape=(21, 128, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Structure 5:  256 Tensor(\"strided_slice_1326:0\", shape=(84, 128, 64, 64), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1327:0\", shape=(84, 128, 64, 64), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1328:0\", shape=(21, 64, 64, 64), dtype=float32, device=/device:GPU:0) Tensor(\"strided_slice_1329:0\", shape=(21, 64, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Generator output 5 final:  Tensor(\"mul_274:0\", shape=(84, 128, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Generator output 6:  Tensor(\"Generator.6_27/NHWC_to_NCHW:0\", shape=(84, 3, 128, 128), dtype=float32, device=/device:GPU:0)\n",
      "Generator output final:  Tensor(\"Tanh_201:0\", shape=(84, 3, 128, 128), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "fake_data:  Tensor(\"Reshape_495:0\", shape=(84, 49152), dtype=float32, device=/device:GPU:0) 84 2 Tensor(\"Reshape_487:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "fake_labels:  Tensor(\"Cast_73:0\", shape=(84, 2), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1:  Tensor(\"Discriminator.1_27/BiasAdd:0\", shape=(84, 128, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 1 nonlinear:  Tensor(\"Maximum_64:0\", shape=(84, 128, 64, 64), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n",
      "Discriminator output 2:  Tensor(\"Discriminator.2_39/BiasAdd:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 bn:  Tensor(\"batchnorm_39/add_1:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "Discriminator output 2 nonlinear:  Tensor(\"Maximum_65:0\", shape=(84, 128, 32, 32), dtype=float32, device=/device:GPU:0)\n",
      "#######################\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Depth of input (128) is not a multiple of input depth of filter (256) for 'Discriminator.3_14/Conv2D' (op: 'Conv2D') with input shapes: [84,128,32,32], [5,5,256,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Depth of input (128) is not a multiple of input depth of filter (256) for 'Discriminator.3_14/Conv2D' (op: 'Conv2D') with input shapes: [84,128,32,32], [5,5,256,512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-307-c4d42fd8c9b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# set up discrimnator results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mdisc_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_fake_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disc fake: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_fake_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mdisc_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_real_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-304-43909a285bec>\u001b[0m in \u001b[0;36mkACGANDiscriminator\u001b[0;34m(inputs, numClasses, dim, bn, nonlinearity)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#######################'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Discriminator.3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m#     output = lib.ops.conv2d.Conv2D(\"Discriminator.3\", dim,  2 * dim, 5, output, stride=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Discriminator output 3: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/Masters-thesis/AC-WGAN/tflib/ops/conv2d.py\u001b[0m in \u001b[0;36mConv2D\u001b[0;34m(name, input_dim, output_dim, filter_size, inputs, he_init, mask_type, stride, weightnorm, biases, gain)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NCHW\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         )\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m   1072\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Depth of input (128) is not a multiple of input depth of filter (256) for 'Discriminator.3_14/Conv2D' (op: 'Conv2D') with input shapes: [84,128,32,32], [5,5,256,512]."
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n",
    "    print('started ...')\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, DIM, DIM])\n",
    "    all_real_label_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    generated_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "    sample_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, CLASSES])\n",
    "\n",
    "    split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n",
    "    split_real_label_conv = tf.split(all_real_label_conv, len(DEVICES))\n",
    "    split_generated_labels_conv = tf.split(generated_labels_conv, len(DEVICES))\n",
    "    split_sample_labels_conv = tf.split(sample_labels_conv, len(DEVICES))\n",
    "\n",
    "    gen_costs, disc_costs = [], []\n",
    "\n",
    "    for device_index, (device, real_data_conv, real_label_conv) in enumerate(\n",
    "        zip(DEVICES, split_real_data_conv, split_real_label_conv)\n",
    "    ):\n",
    "        with tf.device(device):\n",
    "\n",
    "            real_data = tf.reshape(\n",
    "                2 * ((tf.cast(real_data_conv, tf.float32) / 255.0) - 0.5),\n",
    "                [BATCH_SIZE // len(DEVICES), OUTPUT_DIM],\n",
    "            )\n",
    "            print('real_data: ', real_data)\n",
    "            real_labels = tf.reshape(\n",
    "                real_label_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('real_labels: ', real_labels)\n",
    "            generated_labels = tf.reshape(\n",
    "                split_generated_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('generated_labels: ', generated_labels)\n",
    "            sample_labels = tf.reshape(\n",
    "                split_sample_labels_conv, [BATCH_SIZE // len(DEVICES), CLASSES]\n",
    "            )\n",
    "            print('sample_labels: ', sample_labels)\n",
    "            fake_data, fake_labels = Generator(\n",
    "                BATCH_SIZE // len(DEVICES), CLASSES, generated_labels\n",
    "            )\n",
    "#             print(real_data,real_labels,generated_labels,sample_labels,fake_data, fake_labels)\n",
    "            print('fake_data: ', fake_data,BATCH_SIZE // len(DEVICES), CLASSES, generated_labels)\n",
    "            print('fake_labels: ', fake_labels)\n",
    "            # set up discrimnator results\n",
    "\n",
    "            disc_fake, disc_fake_class = Discriminator(fake_data, CLASSES)\n",
    "            print('disc fake: ', disc_fake, disc_fake_class)\n",
    "            disc_real, disc_real_class = Discriminator(real_data, CLASSES)\n",
    "            print('disc real: ', disc_real, disc_real_class)\n",
    "            prediction = tf.argmax(disc_fake_class, 1)\n",
    "            print('prediction 1: ', prediction, disc_fake_class)\n",
    "            correct_answer = tf.argmax(fake_labels, 1)\n",
    "            print('correct 1: ', correct_answer, fake_labels)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 1: ', equality)\n",
    "            genAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            print('accuracy 1: ', genAccuracy)\n",
    "            \n",
    "            prediction = tf.argmax(disc_real_class, 1)\n",
    "            print('prediction 2: ', prediction)\n",
    "            print('disc real class: ', disc_real_class)\n",
    "            correct_answer = tf.argmax(real_labels, 1)\n",
    "            print('correct 2: ', correct_answer, real_labels)\n",
    "#             equality = tf.equal(correct_answer, prediction)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('equality 2: ', equality)\n",
    "            realAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            print('accuracy 2: ', equality)\n",
    "            gen_cost = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            gen_cost_test = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost_test = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            generated_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_fake_class, labels=fake_labels\n",
    "                )\n",
    "            )\n",
    "\n",
    "            real_class_cost = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=disc_real_class, labels=real_labels\n",
    "                )\n",
    "            )\n",
    "            gen_cost += generated_class_cost\n",
    "            disc_cost += real_class_cost\n",
    "\n",
    "            alpha = tf.random_uniform(\n",
    "                shape=[BATCH_SIZE // len(DEVICES), 1], minval=0.0, maxval=1.0\n",
    "            )\n",
    "            differences = fake_data - real_data\n",
    "            interpolates = real_data + (alpha * differences)\n",
    "            gradients = tf.gradients(\n",
    "                Discriminator(interpolates, CLASSES)[0], [interpolates]\n",
    "            )[0]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes - 1.0) ** 2)\n",
    "            disc_cost += LAMBDA * gradient_penalty\n",
    "\n",
    "            real_class_cost_gradient = real_class_cost * 50 + LAMBDA * gradient_penalty\n",
    "\n",
    "            gen_costs.append(gen_cost)\n",
    "            disc_costs.append(disc_cost)\n",
    "\n",
    "    gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "    disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
    "\n",
    "    gen_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        gen_cost,\n",
    "        var_list=lib.params_with_name(\"Generator\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    disc_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        disc_cost,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    class_train_op = tf.train.AdamOptimizer(\n",
    "        learning_rate=1e-4, beta1=0.5, beta2=0.9\n",
    "    ).minimize(\n",
    "        real_class_cost_gradient,\n",
    "        var_list=lib.params_with_name(\"Discriminator.\"),\n",
    "        colocate_gradients_with_ops=True,\n",
    "    )\n",
    "    # For generating samples\n",
    "\n",
    "    fixed_noise = tf.constant(\n",
    "        np.random.normal(size=(BATCH_SIZE, 128)).astype(\"float32\")\n",
    "    )\n",
    "    all_fixed_noise_samples = []\n",
    "    for device_index, device in enumerate(DEVICES):\n",
    "        n_samples = BATCH_SIZE // len(DEVICES)\n",
    "        all_fixed_noise_samples.append(\n",
    "            Generator(\n",
    "                n_samples,\n",
    "                CLASSES,\n",
    "                sample_labels,\n",
    "                noise=fixed_noise[\n",
    "                    device_index * n_samples : (device_index + 1) * n_samples\n",
    "                ],\n",
    "            )[0]\n",
    "        )\n",
    "        if tf.__version__.startswith(\"1.\"):\n",
    "            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n",
    "        else:\n",
    "            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
    "\n",
    "    def generate_image(iteration):\n",
    "        # this might be where we add the conditionality\n",
    "        for i in range(CLASSES):\n",
    "            curLabel = genRandomLabels(BATCH_SIZE, CLASSES, condition=i)\n",
    "            samples = session.run(\n",
    "                all_fixed_noise_samples, feed_dict={sample_labels: curLabel}\n",
    "            )\n",
    "            samples = ((samples + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "            lib.save_images.save_images(\n",
    "                samples.reshape((BATCH_SIZE, 3, DIM, DIM)),\n",
    "                \"generated/samples_{}_{}.png\".format(str(i), iteration),\n",
    "            )\n",
    "\n",
    "    # Dataset iterator\n",
    "#     train_gen, dev_gen = lib.wikiart_genre.load(BATCH_SIZE)\n",
    "    train_gen, dev_gen = load(BATCH_SIZE)\n",
    "\n",
    "    def softmax_cross_entropy(logit, y):\n",
    "        return -tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y)\n",
    "        )\n",
    "\n",
    "    def inf_train_gen():\n",
    "        while True:\n",
    "            for (images, labels) in train_gen():\n",
    "                yield images, labels\n",
    "\n",
    "    _sample_labels = genRandomLabels(BATCH_SIZE, CLASSES)\n",
    "    # Save a batch of ground-truth samples\n",
    "    _x, _y = next(train_gen())\n",
    "    _x_r = session.run(real_data, feed_dict={all_real_data_conv: _x})\n",
    "    _x_r = ((_x_r + 1.0) * (255.99 / 2)).astype(\"int32\")\n",
    "    lib.save_images.save_images(\n",
    "        _x_r.reshape((BATCH_SIZE, 3, DIM, DIM)), \"generated/samples_groundtruth.png\"\n",
    "    )\n",
    "\n",
    "    session.run(\n",
    "        tf.initialize_all_variables(),\n",
    "        feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "    )\n",
    "    gen = train_gen()\n",
    "\n",
    "    for iterp in range(PREITERATIONS):\n",
    "        _data, _labels = next(gen)\n",
    "        _, accuracy = session.run(\n",
    "            [disc_train_op, realAccuracy],\n",
    "            feed_dict={\n",
    "                all_real_data_conv: _data,\n",
    "                all_real_label_conv: _labels,\n",
    "                generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "            },\n",
    "        )\n",
    "        if iterp % 100 == 99:\n",
    "            print(\"pretraining accuracy: \" + str(accuracy))\n",
    "\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(\n",
    "                gen_train_op,\n",
    "                feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)},\n",
    "            )\n",
    "        # Train critic\n",
    "        disc_iters = CRITIC_ITERS\n",
    "        for i in range(disc_iters):\n",
    "            _data, _labels = next(gen)\n",
    "            (\n",
    "                _disc_cost,\n",
    "                _disc_cost_test,\n",
    "                class_cost_test,\n",
    "                gen_class_cost,\n",
    "                _gen_cost_test,\n",
    "                _genAccuracy,\n",
    "                _realAccuracy,\n",
    "                _,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                    disc_train_op,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: _data,\n",
    "                    all_real_label_conv: _labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "\n",
    "        lib.plot.plot(\"train disc cost\", _disc_cost)\n",
    "        lib.plot.plot(\"time\", time.time() - start_time)\n",
    "        lib.plot.plot(\"wgan train disc cost\", _disc_cost_test)\n",
    "        lib.plot.plot(\"train class cost\", class_cost_test)\n",
    "        lib.plot.plot(\"generated class cost\", gen_class_cost)\n",
    "        lib.plot.plot(\"gen cost cost\", _gen_cost_test)\n",
    "        lib.plot.plot(\"gen accuracy\", _genAccuracy)\n",
    "        lib.plot.plot(\"real accuracy\", _realAccuracy)\n",
    "\n",
    "        if (iteration % 100 == 99 and iteration < 1000) or iteration % 1000 == 999:\n",
    "            t = time.time()\n",
    "            dev_disc_costs = []\n",
    "            images, labels = next(dev_gen())\n",
    "            (\n",
    "                _dev_disc_cost,\n",
    "                _dev_disc_cost_test,\n",
    "                _class_cost_test,\n",
    "                _gen_class_cost,\n",
    "                _dev_gen_cost_test,\n",
    "                _dev_genAccuracy,\n",
    "                _dev_realAccuracy,\n",
    "            ) = session.run(\n",
    "                [\n",
    "                    disc_cost,\n",
    "                    disc_cost_test,\n",
    "                    real_class_cost,\n",
    "                    generated_class_cost,\n",
    "                    gen_cost_test,\n",
    "                    genAccuracy,\n",
    "                    realAccuracy,\n",
    "                ],\n",
    "                feed_dict={\n",
    "                    all_real_data_conv: images,\n",
    "                    all_real_label_conv: labels,\n",
    "                    generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES),\n",
    "                },\n",
    "            )\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot(\"dev disc cost\", np.mean(dev_disc_costs))\n",
    "            lib.plot.plot(\"wgan dev disc cost\", _dev_disc_cost_test)\n",
    "            lib.plot.plot(\"dev class cost\", _class_cost_test)\n",
    "            lib.plot.plot(\"dev generated class cost\", _gen_class_cost)\n",
    "            lib.plot.plot(\"dev gen  cost\", _dev_gen_cost_test)\n",
    "            lib.plot.plot(\"dev gen accuracy\", _dev_genAccuracy)\n",
    "            lib.plot.plot(\"dev real accuracy\", _dev_realAccuracy)\n",
    "\n",
    "        if iteration % 100 == 999:\n",
    "            generate_image(iteration)\n",
    "            # Can add generate_good_images method in here if desired\n",
    "\n",
    "        if (iteration < 10) or (iteration % 100 == 99):\n",
    "            lib.plot.flush()\n",
    "\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172265b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c85886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb5b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd219c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
