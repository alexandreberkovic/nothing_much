{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "486e0e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Creates batches of images to feed into the training network conditioned by genre, uses upsampling when creating batches to account for uneven distributions \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b8ba451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e05e950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "963fb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimension of images you want to be passed in to the network\n",
    "DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3db1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your own path to images\n",
    "# src_img_path  = Path('/home/ec2-user/SageMaker/genre-128')\n",
    "src_img_path  = Path('/home/ec2-user/SageMaker/portrait_landscape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a332ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(src_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "615dfcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14971"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(src_img_path,'1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1909ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary should be updated to hold the absolute number of images associated with each genre used during training\n",
    "styles = {\n",
    "    \"portraits\": 14981,\n",
    "    \"landscapes\": 14971\n",
    "}\n",
    "\n",
    "styleNum = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 1\n",
    "}\n",
    "    \n",
    "curPos = {\n",
    "    \"portraits\": 0,\n",
    "    \"landscapes\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcfeca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "testNums = {}\n",
    "trainNums = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9734d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test set of images made up of 1/20 of the images (per genre)\n",
    "for k, v in styles.items():\n",
    "    # put a twentieth of paintings in here\n",
    "    nums = range(v)\n",
    "    random.shuffle(list(nums))\n",
    "    testNums[k] = nums[0 : v // 20]\n",
    "    trainNums[k] = nums[v // 20 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80da79f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'portraits': range(749, 14981), 'landscapes': range(748, 14971)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0d937dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_gen(gen):\n",
    "    while True:\n",
    "        for (images, labels) in gen():\n",
    "            yield images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aedb1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(files, batch_size, n_classes): # add genre parameter\n",
    "    if batch_size % n_classes != 0:\n",
    "        raise ValueError(\n",
    "            \"Batch size {} must be divisible by num classes {}\".format(batch_size, n_classes)\n",
    "        )\n",
    "\n",
    "    class_batch = batch_size // n_classes\n",
    "\n",
    "    generators = []\n",
    "\n",
    "    def get_epoch():\n",
    "\n",
    "        while True:\n",
    "\n",
    "            images = np.zeros((batch_size, 3, DIM, DIM), dtype=\"int32\")\n",
    "            labels = np.zeros((batch_size, n_classes))\n",
    "            n = 0\n",
    "            for style in styles:\n",
    "#             for style in genre:\n",
    "                styleLabel = styleNum[style]\n",
    "                curr = curPos[style]\n",
    "                for _ in range(class_batch):\n",
    "                    if curr == styles[style]:\n",
    "                        curr = 0\n",
    "                        random.shuffle(list(files[style]))\n",
    "                    img_path = str(Path(src_img_path, str(styleLabel), str(curr) + \".png\"))\n",
    "                    image = Image.open(img_path).convert(mode=\"RGB\")\n",
    "                    image = np.asarray(image)\n",
    "\n",
    "                    images[n % batch_size] = image.transpose(2, 0, 1)\n",
    "                    labels[n % batch_size, int(styleLabel)] = 1\n",
    "                    n += 1\n",
    "                    curr += 1\n",
    "                curPos[style] = curr\n",
    "\n",
    "            # randomize things but keep relationship between a conditioning vector and its associated image\n",
    "            rng_state = np.random.get_state()\n",
    "            np.random.shuffle(images)\n",
    "            np.random.set_state(rng_state)\n",
    "            np.random.shuffle(labels)\n",
    "            yield (images, labels)\n",
    "\n",
    "    return get_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3748aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(batch_size):\n",
    "    return (\n",
    "        make_generator(trainNums, batch_size, len(styles)),\n",
    "        make_generator(testNums, batch_size, len(styles)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92d3726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import time\n",
    "import functools\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "# import tflib.wikiart_genre\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "086a8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu==1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb2fcbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bf700f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19e0a1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9621ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uppercase local vars:\n",
      "\tBATCH_SIZE: 84\n",
      "\tCLASSES: 2\n",
      "\tCRITIC_ITERS: 5\n",
      "\tDEVICES: ['/gpu:0']\n",
      "\tDIM: 128\n",
      "\tITERS: 200000\n",
      "\tLAMBDA: 10\n",
      "\tMODE: acwgan\n",
      "\tN_GPUS: 1\n",
      "\tOUTPUT_DIM: 49152\n",
      "\tPREITERATIONS: 2000\n"
     ]
    }
   ],
   "source": [
    "MODE = \"acwgan\"  # dcgan, wgan, wgan-gp, lsgan\n",
    "genre = ['portraits','landscapes']\n",
    "DIM = 128  # Model dimensionality\n",
    "CRITIC_ITERS = 5  # How many iterations to train the critic for, increase it to 50 later\n",
    "N_GPUS = 1  # Number of GPUs\n",
    "BATCH_SIZE = 84  # Batch size. Must be a multiple of CLASSES and N_GPUS\n",
    "ITERS = 200000  # How many iterations to train for\n",
    "LAMBDA = 10  # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = DIM * DIM * 3  # Number of pixels in each image\n",
    "CLASSES = len(genre)  # Number of classes, for genres probably 14\n",
    "PREITERATIONS = 2000  # Number of preiteration training cycles to run\n",
    "lib.print_model_settings(locals().copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6534cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that directory exists where ground truth and plots will be saved to.\n",
    "Path('generated').mkdir(parents=True, exist_ok=True)\n",
    "Path('models').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e345be9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratorAndDiscriminator():\n",
    "    return kACGANGenerator, kACGANDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a97eca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = [\"/gpu:{}\".format(i) for i in range(N_GPUS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f432bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha * x, x)\n",
    "\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "\n",
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(\n",
    "        name + \".Linear\", n_in, n_out, inputs, initialization=\"he\"\n",
    "    )\n",
    "    return LeakyReLU(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "217d0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batchnorm(name, axes, inputs):\n",
    "\n",
    "    if (\"Discriminator\" in name) and (MODE == \"wgan-gp\" or MODE == \"acwgan\"):\n",
    "        if axes != [0, 2, 3]:\n",
    "            raise Exception(\"Layernorm over non-standard axes is unsupported\")\n",
    "        return lib.ops.layernorm.Layernorm(name, [1, 2, 3], inputs)\n",
    "    else:\n",
    "        return lib.ops.batchnorm.Batchnorm(name, axes, inputs, fused=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b30cacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixcnn_gated_nonlinearity(name, output_dim, a, b, c=None, d=None):\n",
    "    if c is not None and d is not None:\n",
    "        a = a + c\n",
    "        b = b + d\n",
    "    result = tf.sigmoid(a) * tf.tanh(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf6022e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SubpixelConv2D(*args, **kwargs):\n",
    "    kwargs[\"output_dim\"] = 4 * kwargs[\"output_dim\"]\n",
    "    output = lib.ops.conv2d.Conv2D(*args, **kwargs)\n",
    "    output = tf.transpose(output, [0, 2, 3, 1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0, 3, 1, 2])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a43eb73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResidualBlock(name, input_dim, output_dim, filter_size, inputs, resample=None, he_init=True):\n",
    "    \"\"\"\n",
    "    resample: None, 'down', or 'up'\n",
    "    \"\"\"\n",
    "    if resample=='down':\n",
    "        conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n",
    "        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim//2)\n",
    "        conv_1b       = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim//2, output_dim=output_dim//2, stride=2)\n",
    "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=output_dim//2, output_dim=output_dim)\n",
    "    elif resample=='up':\n",
    "        conv_shortcut = SubpixelConv2D\n",
    "        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim//2)\n",
    "        conv_1b       = functools.partial(lib.ops.deconv2d.Deconv2D, input_dim=input_dim//2, output_dim=output_dim//2)\n",
    "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=output_dim//2, output_dim=output_dim)\n",
    "    elif resample==None:\n",
    "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
    "        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim,  output_dim=input_dim//2)\n",
    "        conv_1b       = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim//2,  output_dim=output_dim//2)\n",
    "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim//2, output_dim=output_dim)\n",
    "\n",
    "    else:\n",
    "        raise Exception('invalid resample value')\n",
    "\n",
    "    if output_dim==input_dim and resample==None:\n",
    "        shortcut = inputs # Identity skip-connection\n",
    "    else:\n",
    "        shortcut = conv_shortcut(name+'.Shortcut', input_dim=input_dim, output_dim=output_dim, filter_size=1,\n",
    "                                 he_init=False, biases=True, inputs=inputs)\n",
    "\n",
    "    output = inputs\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1(name+'.Conv1', filter_size=1, inputs=output, he_init=he_init, weightnorm=False)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_1b(name+'.Conv1B', filter_size=filter_size, inputs=output, he_init=he_init, weightnorm=False)\n",
    "    output = tf.nn.relu(output)\n",
    "    output = conv_2(name+'.Conv2', filter_size=1, inputs=output, he_init=he_init, weightnorm=False, biases=False)\n",
    "    output = Batchnorm(name+'.BN', [0,2,3], output)\n",
    "\n",
    "    return shortcut + (0.3*output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1aac0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANGenerator(n_samples, numClasses, labels, noise=None, dim=DIM, bn=True, nonlinearity=tf.nn.relu, condition=None):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    labels = tf.cast(labels, tf.float32)        \n",
    "    noise = tf.concat([noise, labels], 1)\n",
    "\n",
    "    dim//=2\n",
    "# new\n",
    "#######################\n",
    "    print('#######################')\n",
    "    output = lib.ops.linear.Linear('Generator.Input', 128+numClasses, 16*2*2*dim*2, noise) #probs need to recalculate dimensions\n",
    "    print('Generator linear output 0: ', output )\n",
    "    output = tf.reshape(output, [-1, 16*dim*2, 2, 2])\n",
    "    print('Generator output reshape 0: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN0', [0,2,3], output)\n",
    "    condition = lib.ops.linear.Linear('Generator.cond0', numClasses, 16*2*2*dim*2, labels,biases=False)\n",
    "    print('Generator condition 0: ', condition )\n",
    "    condition = tf.reshape(condition, [-1, 16*dim*2, 2, 2])\n",
    "    print('Generator condition reshape 0: ', condition )\n",
    "    output = pixcnn_gated_nonlinearity('Generator.nl0', 32*dim, output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n",
    "    print('Generator output 0 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "#    output = lib.ops.linear.Linear('Generator.Input', 128+numClasses, 8*4*4*dim*2, noise) #probs need to recalculate dimensions\n",
    "#    output = tf.reshape(output, [-1, 8*dim*2, 4, 4])\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.1', 16*dim, 8*dim*2, 5, output)\n",
    "    print('Generator output 1: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN1', [0,2,3], output)\n",
    "    condition = lib.ops.linear.Linear('Generator.cond1', numClasses, 8*4*4*dim*2, labels,biases=False)\n",
    "    print('Generator condition 1: ', condition )\n",
    "    condition = tf.reshape(condition, [-1, 8*dim*2, 4, 4])\n",
    "    print('Generator condition reshape 1: ', condition )\n",
    "    output = pixcnn_gated_nonlinearity('Generator.nl1', 16*dim, output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n",
    "    print('Generator output 1 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.2', 8*dim, 4*dim*2, 5, output)\n",
    "    print('Generator output 2: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN2', [0,2,3], output)\n",
    "    condition = lib.ops.linear.Linear('Generator.cond2', numClasses, 4*8*8*dim*2, labels)\n",
    "    print('Generator condition 2: ', condition )\n",
    "    condition = tf.reshape(condition, [-1, 4*dim*2, 8, 8])\n",
    "    print('Generator condition 2 reshape: ', condition )\n",
    "    output = pixcnn_gated_nonlinearity('Generator.nl2', 4*dim,output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n",
    "    print('Generator output 2 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.3', 4*dim, 2*dim*2, 5, output)\n",
    "    print('Generator output 3: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN3', [0,2,3], output)\n",
    "    condition = lib.ops.linear.Linear('Generator.cond3', numClasses, 2*16*16*dim*2, labels)\n",
    "    print('Generator condition 3: ', condition )\n",
    "    condition = tf.reshape(condition, [-1, 2*dim*2, 16, 16])\n",
    "    print('Generator condition 3 reshape: ', condition )\n",
    "    output = pixcnn_gated_nonlinearity('Generator.nl3', 2*dim,output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n",
    "    print('Generator output 3 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.4', 2*dim, dim*2, 5, output)\n",
    "    print('Generator output 4: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN4', [0,2,3], output)\n",
    "    condition = lib.ops.linear.Linear('Generator.cond4', numClasses, 32*32*dim*2, labels)\n",
    "    print('Generator condition 4: ', condition )\n",
    "    condition = tf.reshape(condition, [-1, dim*2, 32, 32])\n",
    "    print('Generator condition 4 reshape: ', condition )\n",
    "    output = pixcnn_gated_nonlinearity('Generator.nl4', dim, output[:,::2], output[:,1::2], condition[:,::2], condition[:,1::2])\n",
    "    print('Generator output 4 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.5', dim, 3, 5, output)\n",
    "    print('Generator output 5: ', output )\n",
    "    output = tf.tanh(output)\n",
    "    print('Generator output 5 final: ', output )\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "#######################\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM]), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e08e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kACGANDiscriminator(inputs, numClasses, dim=DIM, bn=True, nonlinearity=LeakyReLU):\n",
    "#     dim//=2\n",
    "    output = tf.reshape(inputs, [-1, 3, dim, dim])\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "#######################   \n",
    "    print('#######################')\n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.1', 3, dim, 5, output, stride=2)\n",
    "    print('Discriminator output 1: ', output )\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 1 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.2', dim, 2*dim, 5, output, stride=2)\n",
    "    print('Discriminator output 2: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Discriminator.BN2', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 2 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.3', 2*dim, 4*dim, 5, output, stride=2)\n",
    "    print('Discriminator output 3: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Discriminator.BN3', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 3 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "    \n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.4', 4*dim, 8*dim, 5, output, stride=2)\n",
    "    print('Discriminator output 4: ', output )\n",
    "    if bn:\n",
    "        output = Batchnorm('Discriminator.BN4', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "    print('Discriminator output 4 final: ', output )\n",
    "    print('#######################')\n",
    "#######################\n",
    "    finalLayer = tf.reshape(output, [-1, 4*4*8*dim])\n",
    "    print('Discriminator final layer: ', finalLayer )\n",
    "    sourceOutput = lib.ops.linear.Linear('Discriminator.sourceOutput', 4*4*8*dim, 1, finalLayer)\n",
    "    print('Discriminator source output: ', sourceOutput )\n",
    "    classOutput = lib.ops.linear.Linear('Discriminator.classOutput', 4*4*8*dim, numClasses, finalLayer)\n",
    "    print('Discriminator class output: ', classOutput )\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "    print('#######################')\n",
    "#######################\n",
    "    return (tf.reshape(sourceOutput, [-1]), tf.reshape(classOutput, [-1, numClasses]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "238c6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandomLabels(n_samples, numClasses, condition=None):\n",
    "    labels = np.zeros([BATCH_SIZE, CLASSES], dtype=np.float32)\n",
    "    for i in range(n_samples):\n",
    "        if condition is not None:\n",
    "            labelNum = condition\n",
    "        else:\n",
    "            labelNum = randint(0, numClasses - 1)\n",
    "        labels[i, labelNum] = 1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6791d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator, Discriminator = GeneratorAndDiscriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a18a1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real data:  Tensor(\"Reshape_93:0\", shape=(84, 49152), dtype=float32, device=/device:GPU:0)\n",
      "Real labels:  Tensor(\"Reshape_94:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "Generated labels:  Tensor(\"Reshape_95:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n",
      "Sample labels:  Tensor(\"Reshape_96:0\", shape=(84, 2), dtype=int32, device=/device:GPU:0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ResnetGenerator() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-6aae572370f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample labels: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mfake_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fake data: {}, {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#set up discrimnator results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ResnetGenerator() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as session:\n",
    "\n",
    "    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, DIM, DIM])\n",
    "    all_real_label_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE,CLASSES])\n",
    "\n",
    "    generated_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE,CLASSES])\n",
    "    sample_labels_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE,CLASSES])\n",
    "\n",
    "    if tf.__version__.startswith('1.'):\n",
    "        split_real_data_conv = tf.split(all_real_data_conv, len(DEVICES))\n",
    "        split_real_label_conv = tf.split(all_real_label_conv, len(DEVICES))\n",
    "        split_generated_labels_conv = tf.split(generated_labels_conv, len(DEVICES))\n",
    "        split_sample_labels_conv = tf.split(sample_labels_conv, len(DEVICES))\n",
    "    else:\n",
    "        split_real_data_conv = tf.split(0, len(DEVICES), all_real_data_conv)\n",
    "        split_real_data_label = tf.split(0, len(DEVICES), all_real_data_conv)\n",
    "        split_generated_labels = tf.split(0, len(DEVICES), generated_labels_conv)\n",
    "        split_sample_labels = tf.split(0, len(DEVICES), sample_labels_conv)\n",
    "\n",
    "    gen_costs, disc_costs = [],[]\n",
    "\n",
    "    for device_index, (device, real_data_conv, real_label_conv) in enumerate(zip(DEVICES, split_real_data_conv, split_real_label_conv)):\n",
    "        with tf.device(device):\n",
    "\n",
    "            real_data = tf.reshape(2*((tf.cast(real_data_conv, tf.float32)/255.)-.5), [BATCH_SIZE//len(DEVICES), OUTPUT_DIM])\n",
    "            real_labels = tf.reshape(real_label_conv, [BATCH_SIZE//len(DEVICES), CLASSES])\n",
    "            print(\"Real data: \", real_data)\n",
    "            print(\"Real labels: \", real_labels)\n",
    "            generated_labels = tf.reshape(split_generated_labels_conv, [BATCH_SIZE//len(DEVICES), CLASSES])\n",
    "            sample_labels = tf.reshape(split_sample_labels_conv, [BATCH_SIZE//len(DEVICES), CLASSES])\n",
    "            print(\"Generated labels: \", generated_labels)\n",
    "            print(\"Sample labels: \", sample_labels)\n",
    "\n",
    "            fake_data, fake_labels = Generator(BATCH_SIZE//len(DEVICES), CLASSES, generated_labels)\n",
    "            print(\"Fake data: {}, {}\".format(fake_data,fake_labels))\n",
    "            #set up discrimnator results\n",
    "            print('Classes: ', CLASSES)\n",
    "\n",
    "            disc_fake,disc_fake_class = Discriminator(fake_data, CLASSES)\n",
    "            print(\"Fake dsicriminator: {}, {}\".format(disc_fake,disc_fake_class))\n",
    "            disc_real,disc_real_class = Discriminator(real_data, CLASSES)\n",
    "            print(\"Real dsicriminator: {}, {}\".format(disc_real,disc_real_class))\n",
    "\n",
    "            print(\"Fake shapes: fake data {}, fake disc {}, fake disc class {}\".format(fake_data.shape,disc_fake.shape,disc_fake_class.shape))\n",
    "            print(\"Real shapes: real data {}, real disc {}, real disc class {}\".format(real_data.shape,disc_real.shape,disc_real_class.shape))\n",
    "\n",
    "\n",
    "            prediction = tf.argmax(disc_fake_class, 1)\n",
    "            print('Prediction 1: ', prediction)\n",
    "            correct_answer = tf.argmax(fake_labels, 1)\n",
    "            print('Correct 1: ', correct_answer)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('Equality 1: ', equality)\n",
    "            genAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "            prediction = tf.argmax(disc_real_class, 1)\n",
    "            print('Prediction 2: ', prediction)\n",
    "            correct_answer = tf.argmax(real_labels, 1)\n",
    "            print('Correct 2: ', correct_answer)\n",
    "            equality = tf.equal(prediction, correct_answer)\n",
    "            print('Equality 2: ', equality)\n",
    "            realAccuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "\n",
    "            gen_cost = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            gen_cost_test = -tf.reduce_mean(disc_fake)\n",
    "            disc_cost_test = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "            generated_class_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=disc_fake_class,\n",
    "                                                                                              labels=fake_labels))\n",
    "\n",
    "\n",
    "            real_class_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=disc_real_class,\n",
    "                                                                                              labels=real_labels))\n",
    "            gen_cost += generated_class_cost\n",
    "            disc_cost += real_class_cost\n",
    "\n",
    "            alpha = tf.random_uniform(\n",
    "                shape=[BATCH_SIZE//len(DEVICES),1],\n",
    "                minval=0.,\n",
    "                maxval=1.\n",
    "            )\n",
    "            differences = fake_data - real_data\n",
    "            interpolates = real_data + (alpha*differences)\n",
    "            gradients = tf.gradients(Discriminator(interpolates, CLASSES)[0], [interpolates])[0]\n",
    "            slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "            gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "            disc_cost += LAMBDA*gradient_penalty\n",
    "\n",
    "            real_class_cost_gradient = real_class_cost*50 + LAMBDA*gradient_penalty\n",
    "\n",
    "\n",
    "            gen_costs.append(gen_cost)\n",
    "            disc_costs.append(disc_cost)\n",
    "\n",
    "    gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "    disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
    "\n",
    "    gen_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(gen_cost,\n",
    "                                                                                             var_list=lib.params_with_name('Generator'),\n",
    "                                                                                             colocate_gradients_with_ops=True)\n",
    "    disc_train_op = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(disc_cost,\n",
    "                                                                                              var_list=lib.params_with_name('Discriminator.'),\n",
    "                                                                                              colocate_gradients_with_ops=True)\n",
    "    class_train_op =  tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9).minimize(real_class_cost_gradient,\n",
    "                                                                                                var_list=lib.params_with_name('Discriminator.'),\n",
    "                                                                                                colocate_gradients_with_ops=True)\n",
    "    # For generating samples\n",
    "\n",
    "    fixed_noise = tf.constant(np.random.normal(size=(BATCH_SIZE, 128)).astype('float32'))\n",
    "    all_fixed_noise_samples = []\n",
    "    for device_index, device in enumerate(DEVICES):\n",
    "        n_samples = BATCH_SIZE // len(DEVICES)\n",
    "        all_fixed_noise_samples.append(Generator(n_samples, CLASSES, sample_labels,noise=fixed_noise[device_index*n_samples:(device_index+1)*n_samples])[0])\n",
    "        if tf.__version__.startswith('1.'):\n",
    "            all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n",
    "        else:\n",
    "            all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
    "\n",
    "\n",
    "    def generate_image(iteration):\n",
    "        for i in range(CLASSES):\n",
    "            curLabel= genRandomLabels(BATCH_SIZE,CLASSES,condition=i)\n",
    "            samples = session.run(all_fixed_noise_samples, feed_dict={sample_labels: curLabel})\n",
    "            samples = ((samples+1.)*(255.99/2)).astype('int32')\n",
    "            lib.save_images.save_images(samples.reshape((BATCH_SIZE, 3, DIM, DIM)), 'generated/samples_{}_{}.png'.format(str(i), iteration))\n",
    "            lib.save_images.save_images_ind(samples.reshape((BATCH_SIZE, 3, DIM, DIM)), 'generated/ind/samples_{}_{}_'.format(str(i), iteration)+'{}.png')\n",
    "\n",
    "    def generate_good_images(iteration,thresh=.95):\n",
    "        NUM_TO_MAKE = BATCH_SIZE\n",
    "        TRIES = BATCH_SIZE*5\n",
    "        CONF_THRESH = thresh\n",
    "        for i in range(CLASSES):\n",
    "            l = 0\n",
    "            curLabel= genRandomLabels(BATCH_SIZE,CLASSES,condition=i)\n",
    "            j = 0\n",
    "            images = None\n",
    "            while(j<NUM_TO_MAKE and l<TRIES):\n",
    "                genr = Generator(BATCH_SIZE, CLASSES, sample_labels)[0]\n",
    "                samples = session.run(genr, feed_dict={sample_labels: curLabel})\n",
    "                samples = np.reshape(samples,[-1, 3, DIM, DIM])\n",
    "                samples = ((samples+1.)*(255.99/2)).astype('int32')\n",
    "                prediction,accuracy = session.run([disc_real_class,realAccuracy] , feed_dict = {all_real_data_conv: samples, all_real_label_conv: curLabel})\n",
    "                guess = np.argmax(prediction,1)\n",
    "                my_equal = np.equal(guess,np.argmax(curLabel,1))\n",
    "                for s,_ in enumerate(prediction):\n",
    "                    prediction[s] = prediction[s]/np.sum(prediction[s])\n",
    "                    confidence = np.amax(prediction,1)\n",
    "                    for k,image in enumerate(samples):\n",
    "                        if guess[k] == i and confidence[k]>CONF_THRESH and j < NUM_TO_MAKE:\n",
    "                            if isinstance(images, np.ndarray):\n",
    "                                images = np.concatenate((images,image),0)\n",
    "                            else:\n",
    "                                images = image\n",
    "                        j+=1\n",
    "                    l += 1\n",
    "                CONF_THRESH = CONF_THRESH * .9\n",
    "            try:\n",
    "                samples = images\n",
    "                lib.save_images.save_images(samples.reshape((-1, 3, DIM, DIM)), 'generated/good_samples_{}_{}.png'.format(str(i),iteration))\n",
    "                lib.save_images.save_images_ind(samples.reshape((-1, 3, DIM, DIM)), 'generated/ind/good_samples_{}_{}_'.format(str(i), iteration)+'{}.png')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "\n",
    "    # Dataset iterator\n",
    "    train_gen, dev_gen = lib.wikiartGenre.load(BATCH_SIZE)\n",
    "\n",
    "    def softmax_cross_entropy(logit, y):\n",
    "        return -tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y))\n",
    "\n",
    "    def inf_train_gen():\n",
    "        while True:\n",
    "            for (images,labels) in train_gen():\n",
    "                yield images,labels\n",
    "\n",
    "\n",
    "    _sample_labels = genRandomLabels(BATCH_SIZE, CLASSES)\n",
    "    # Save a batch of ground-truth samples\n",
    "    _x,_y = next(train_gen())\n",
    "    _x_r = session.run(real_data, feed_dict={all_real_data_conv: _x})\n",
    "    _x_r = ((_x_r+1.)*(255.99/2)).astype('int32')\n",
    "    lib.save_images.save_images(_x_r.reshape((BATCH_SIZE, 3, DIM, DIM)), 'generated/samples_groundtruth.png')\n",
    "\n",
    "\n",
    "\n",
    "    session.run(tf.initialize_all_variables(), feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n",
    "    gen = train_gen()\n",
    "\n",
    "    for iterp in range(PREITERATIONS):\n",
    "        _data, _labels = next(gen)\n",
    "        _ , accuracy = session.run([disc_train_op, realAccuracy],feed_dict = {all_real_data_conv: _data, all_real_label_conv: _labels, generated_labels_conv: genRandomLabels(BATCH_SIZE, CLASSES)})\n",
    "        if iterp % 100 == 99:\n",
    "            print('pretraining accuracy: ' + str(accuracy))\n",
    "\n",
    "\n",
    "    for iteration in range(ITERS):\n",
    "        start_time = time.time()\n",
    "        # Train generator\n",
    "        if iteration > 0:\n",
    "            _ = session.run(gen_train_op, feed_dict={generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n",
    "        # Train critic\n",
    "        disc_iters = CRITIC_ITERS\n",
    "        for i in range(disc_iters):\n",
    "            _data, _labels = next(gen)\n",
    "            _disc_cost, _disc_cost_test, class_cost_test, gen_class_cost, _gen_cost_test, _genAccuracy, _realAccuracy, _ = session.run([disc_cost, disc_cost_test, real_class_cost, generated_class_cost, gen_cost_test, genAccuracy, realAccuracy, disc_train_op], feed_dict={all_real_data_conv: _data, all_real_label_conv: _labels, generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n",
    "\n",
    "        lib.plot.plot('train disc cost', _disc_cost)\n",
    "        lib.plot.plot('time', time.time() - start_time)\n",
    "        lib.plot.plot('wgan train disc cost', _disc_cost_test)\n",
    "        lib.plot.plot('train class cost', class_cost_test)\n",
    "        lib.plot.plot('generated class cost', gen_class_cost)\n",
    "        lib.plot.plot('gen cost cost', _gen_cost_test)\n",
    "        lib.plot.plot('gen accuracy', _genAccuracy)\n",
    "        lib.plot.plot('real accuracy', _realAccuracy)\n",
    "\n",
    "        if (iteration % 100 == 99 and iteration<1000) or iteration % 1000 == 999 :\n",
    "            t = time.time()\n",
    "            dev_disc_costs = []\n",
    "            images, labels = next(dev_gen())\n",
    "            _dev_disc_cost, _dev_disc_cost_test, _class_cost_test, _gen_class_cost, _dev_gen_cost_test, _dev_genAccuracy, _dev_realAccuracy = session.run([disc_cost, disc_cost_test, real_class_cost, generated_class_cost, gen_cost_test, genAccuracy, realAccuracy], feed_dict={all_real_data_conv: images, all_real_label_conv: labels, generated_labels_conv: genRandomLabels(BATCH_SIZE,CLASSES)})\n",
    "            dev_disc_costs.append(_dev_disc_cost)\n",
    "            lib.plot.plot('dev disc cost', np.mean(dev_disc_costs))\n",
    "            lib.plot.plot('wgan dev disc cost', _dev_disc_cost_test)\n",
    "            lib.plot.plot('dev class cost', _class_cost_test)\n",
    "            lib.plot.plot('dev generated class cost', _gen_class_cost)\n",
    "            lib.plot.plot('dev gen  cost', _dev_gen_cost_test)\n",
    "            lib.plot.plot('dev gen accuracy', _dev_genAccuracy)\n",
    "            lib.plot.plot('dev real accuracy', _dev_realAccuracy)\n",
    "\n",
    "\n",
    "        if iteration % 1000 == 999:\n",
    "            generate_image(iteration)\n",
    "            generate_good_images(iteration)\n",
    "            #Can add generate_good_images method in here if desired\n",
    "\n",
    "        if (iteration < 10) or (iteration % 100 == 99):\n",
    "            lib.plot.flush()\n",
    "\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "94714423",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-f0baa932daf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;31m# split_real_data_conv = lib.split(all_real_data_conv, len(DEVICES), axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def nonlinearity(x):\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def Normalize(name, inputs):\n",
    "    if ('Discriminator' in name) and NORMALIZATION_D:\n",
    "        return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs)\n",
    "    elif ('Generator' in name) and NORMALIZATION_G:\n",
    "        return lib.ops.batchnorm.Batchnorm(name,[0,2,3],inputs,fused=True)\n",
    "\n",
    "def ConvMeanPool(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, inputs, he_init=he_init, biases=biases)\n",
    "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "    return output\n",
    "\n",
    "def MeanPoolConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = inputs\n",
    "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
    "    return output\n",
    "\n",
    "def ScaledUpsampleConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = inputs\n",
    "    output = lib.concat([output, output, output, output], axis=1)\n",
    "    output = tf.transpose(output, [0,2,3,1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0,3,1,2])\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases, gain=0.5)\n",
    "    return output\n",
    "\n",
    "def ResidualBlock(name, input_dim, output_dim, filter_size, inputs, resample=None):\n",
    "    \"\"\"\n",
    "    resample: None, 'down', or 'up'\n",
    "    \"\"\"\n",
    "    if resample=='down':\n",
    "        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=input_dim)\n",
    "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim, output_dim=output_dim, stride=2)\n",
    "        # conv_shortcut = functools.partial(lib.ops.conv2d.Conv2D, stride=2)\n",
    "        # conv_2        = functools.partial(ConvMeanPool, input_dim=input_dim, output_dim=output_dim)\n",
    "        conv_shortcut = MeanPoolConv\n",
    "    elif resample=='up':\n",
    "        conv_1        = functools.partial(ScaledUpsampleConv, input_dim=input_dim, output_dim=output_dim)\n",
    "        # conv_1        = functools.partial(lib.ops.deconv2d.Deconv2D, input_dim=input_dim, output_dim=output_dim)\n",
    "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=output_dim, output_dim=output_dim)\n",
    "        conv_shortcut = ScaledUpsampleConv\n",
    "    elif resample==None:\n",
    "        conv_shortcut = lib.ops.conv2d.Conv2D\n",
    "        conv_1        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=input_dim,  output_dim=output_dim)\n",
    "        conv_2        = functools.partial(lib.ops.conv2d.Conv2D, input_dim=output_dim, output_dim=output_dim)\n",
    "    else:\n",
    "        raise Exception('invalid resample value')\n",
    "\n",
    "    if output_dim==input_dim and resample==None:\n",
    "        shortcut = inputs # Identity skip-connection\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "        # shortcut = Normalize(name+'.NShortcut', shortcut)\n",
    "        shortcut = conv_shortcut(name+'.Shortcut', input_dim=input_dim, output_dim=output_dim, filter_size=1, he_init=False, biases=True, inputs=shortcut)\n",
    "\n",
    "    output = inputs\n",
    "    output = Normalize(name+'.N1', output)\n",
    "    output = nonlinearity(output)\n",
    "    output = conv_1(name+'.Conv1', filter_size=filter_size, inputs=output)\n",
    "    output = Normalize(name+'.N2', output)\n",
    "    output = nonlinearity(output)\n",
    "    output = conv_2(name+'.Conv2', filter_size=filter_size, inputs=output)\n",
    "    # output = Normalize(name+'.N3', output)\n",
    "    # return output\n",
    "    return shortcut + output\n",
    "    # return 0.7*(shortcut+output)\n",
    "\n",
    "def ResnetGenerator(n_samples, noise=None):\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    output = lib.ops.linear.Linear('Generator.Input', 128, 4*4*DIM_G_4, noise)\n",
    "    output = tf.reshape(output, [-1, DIM_G_4, 4, 4])\n",
    "\n",
    "    # output = ResidualBlock('Generator.4_1', DIM_G_4, DIM_G_4, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Generator.4_2', DIM_G_4, DIM_G_4, 3, output, resample=None)\n",
    "    output = ResidualBlock('Generator.4_3', DIM_G_4, DIM_G_8, 3, output, resample='up')\n",
    "\n",
    "    # output = ResidualBlock('Generator.8_1', DIM_G_8, DIM_G_8, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Generator.8_2', DIM_G_8, DIM_G_8, 3, output, resample=None)\n",
    "    output = ResidualBlock('Generator.8_3', DIM_G_8, DIM_G_16, 3, output, resample='up')\n",
    "\n",
    "    # output = ResidualBlock('Generator.16_1', DIM_G_16, DIM_G_16, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Generator.16_2', DIM_G_16, DIM_G_16, 3, output, resample=None)\n",
    "    output = ResidualBlock('Generator.16_3', DIM_G_16, DIM_G_32, 3, output, resample='up')\n",
    "\n",
    "    # output = ResidualBlock('Generator.32_1', DIM_G_32, DIM_G_32, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Generator.32_2', DIM_G_32, DIM_G_32, 3, output, resample=None)\n",
    "    output = ResidualBlock('Generator.32_3', DIM_G_32, DIM_G_64, 3, output, resample='up')\n",
    "\n",
    "    output = Normalize('Generator.OutputN', output)\n",
    "    output = nonlinearity(output)\n",
    "    output = ScaledUpsampleConv('Generator.Output', DIM_G_64, 3, 5, output, he_init=False)\n",
    "    # output = lib.ops.deconv2d.Deconv2D('Generator.Output', DIM_G_64, 3, 5, output, he_init=False)\n",
    "\n",
    "    output = tf.tanh(output)\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM])\n",
    "\n",
    "def ResnetDiscriminator(inputs):\n",
    "    output = tf.reshape(inputs, [-1, 3, 128, 128])\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D('Discriminator.Input', 3, DIM_D_64, 5, output, he_init=True, stride=2)\n",
    "\n",
    "    # output = ResidualBlock('Discriminator.64_1', DIM_D_64, DIM_D_64, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Discriminator.64_2', DIM_D_64, DIM_D_64, 3, output, resample=None)\n",
    "    output = ResidualBlock('Discriminator.64_3', DIM_D_64, DIM_D_32, 3, output, resample='down')\n",
    "\n",
    "    # output = ResidualBlock('Discriminator.32_1', DIM_D_32, DIM_D_32, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Discriminator.32_2', DIM_D_32, DIM_D_32, 3, output, resample=None)\n",
    "    output = ResidualBlock('Discriminator.32_3', DIM_D_32, DIM_D_16, 3, output, resample='down')\n",
    "\n",
    "    # output = ResidualBlock('Discriminator.16_1', DIM_D_16, DIM_D_16, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Discriminator.16_2', DIM_D_16, DIM_D_16, 3, output, resample=None)\n",
    "    output = ResidualBlock('Discriminator.16_3', DIM_D_16, DIM_D_8, 3, output, resample='down')\n",
    "\n",
    "    output = ResidualBlock('Discriminator.8_1', DIM_D_8, DIM_D_8, 3, output, resample=None)\n",
    "    output = ResidualBlock('Discriminator.8_2', DIM_D_8, DIM_D_8, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Discriminator.8_3', DIM_D_8, DIM_D_4, 3, output, resample='down')\n",
    "\n",
    "    # output = ResidualBlock('Discriminator.4_1', DIM_D_4, DIM_D_4, 3, output, resample=None)\n",
    "    # output = ResidualBlock('Discriminator.4_2', DIM_D_4, DIM_D_4, 3, output, resample=None)\n",
    "\n",
    "    # output = Normalize('Discriminator.OutputN', output)\n",
    "    # output = output / 10.\n",
    "    output = tf.reduce_mean(output, axis=[2,3])\n",
    "    output = lib.ops.linear.Linear('Discriminator.Output', DIM_D_8, 1, output)\n",
    "\n",
    "    # output = Normalize('Discriminator.OutputN', output)\n",
    "    # output = nonlinearity(output)\n",
    "    # output = tf.reshape(output, [-1, 4*4*DIM_D_4])\n",
    "    # output = lib.ops.linear.Linear('Discriminator.Output', 4*4*DIM_D_4, 1, output)\n",
    "\n",
    "    return tf.reshape(output, [-1])\n",
    "\n",
    "with tf.Session() as session:\n",
    "\n",
    "    Generator, Discriminator = GeneratorAndDiscriminator()\n",
    "\n",
    "    iteration = tf.placeholder(tf.int32, shape=None)\n",
    "    all_real_data_conv = tf.placeholder(tf.int32, shape=[BATCH_SIZE, 3, 128, 128])\n",
    "\n",
    "    if (len(DEVICES)%2==0) and (len(DEVICES)>=2):\n",
    "\n",
    "        fake_data_splits = []\n",
    "        for device in DEVICES:\n",
    "            with tf.device(device):\n",
    "                fake_data_splits.append(Generator(BATCH_SIZE/len(DEVICES)))\n",
    "        # fake_data = tf.concat(fake_data_splits, axis=0)\n",
    "        # fake_data_splits = tf.split(fake_data, len(DEVICES))\n",
    "\n",
    "        all_real_data = tf.reshape(2*((tf.cast(all_real_data_conv, tf.float32)/255.)-.5), [BATCH_SIZE, OUTPUT_DIM])\n",
    "        all_real_data_splits = tf.split(all_real_data, len(DEVICES)/2)\n",
    "\n",
    "        DEVICES_B = DEVICES[:len(DEVICES)/2]\n",
    "        DEVICES_A = DEVICES[len(DEVICES)/2:]\n",
    "\n",
    "        disc_costs = []\n",
    "        for i, device in enumerate(DEVICES_A):\n",
    "            with tf.device(device):\n",
    "                real_and_fake_data = lib.concat([all_real_data_splits[i]] + [fake_data_splits[i]] + [fake_data_splits[len(DEVICES_A)+i]], axis=0)\n",
    "                disc_all = Discriminator(real_and_fake_data)\n",
    "                disc_real = disc_all[:BATCH_SIZE/len(DEVICES_A)]\n",
    "                disc_fake = disc_all[BATCH_SIZE/len(DEVICES_A):]\n",
    "                disc_costs.append(tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real))\n",
    "\n",
    "        for i, device in enumerate(DEVICES_B):\n",
    "            with tf.device(device):\n",
    "                real_data = tf.identity(all_real_data_splits[i]) # transfer from gpu0\n",
    "                fake_data__ = lib.concat([fake_data_splits[i], fake_data_splits[len(DEVICES_A)+i]], axis=0)\n",
    "                alpha = tf.random_uniform(\n",
    "                    shape=[BATCH_SIZE/len(DEVICES_A),1], \n",
    "                    minval=0.,\n",
    "                    maxval=1.\n",
    "                )\n",
    "                differences = fake_data__ - real_data\n",
    "                interpolates = real_data + (alpha*differences)\n",
    "                gradients = tf.gradients(Discriminator(interpolates), [interpolates])[0]\n",
    "                slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "                # print \"WARNING NO LIPSCHITZ PENALTY\"\n",
    "                gradient_penalty = 10.*tf.reduce_mean((slopes-1.)**2)\n",
    "                disc_costs.append(gradient_penalty)\n",
    "\n",
    "        disc_cost = tf.add_n(disc_costs) / len(DEVICES_A)\n",
    "\n",
    "        if DECAY:\n",
    "            decay = tf.maximum(0., 1.-(tf.cast(iteration, tf.float32)/ITERS))\n",
    "        else:\n",
    "            decay = 1.\n",
    "        disc_train_op = tf.train.AdamOptimizer(learning_rate=LR*decay, beta1=MOMENTUM_D, beta2=0.9).minimize(disc_cost, var_list=lib.params_with_name('Discriminator.'), colocate_gradients_with_ops=True)\n",
    "\n",
    "        gen_costs = []\n",
    "        for device in DEVICES:\n",
    "            with tf.device(device):\n",
    "                gen_costs.append(-tf.reduce_mean(Discriminator(Generator(GEN_BS_MULTIPLE*BATCH_SIZE/len(DEVICES)))))\n",
    "        gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "        gen_train_op = tf.train.AdamOptimizer(learning_rate=LR*decay, beta1=MOMENTUM_G, beta2=0.9).minimize(gen_cost, var_list=lib.params_with_name('Generator'), colocate_gradients_with_ops=True)\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise Exception()\n",
    "        # split_real_data_conv = lib.split(all_real_data_conv, len(DEVICES), axis=0)\n",
    "\n",
    "        # gen_costs, disc_costs = [],[]\n",
    "\n",
    "        # for device_index, (device, real_data_conv) in enumerate(zip(DEVICES, split_real_data_conv)):\n",
    "        #     with tf.device(device):\n",
    "\n",
    "        #         real_data = tf.reshape(2*((tf.cast(real_data_conv, tf.float32)/255.)-.5), [BATCH_SIZE/len(DEVICES), OUTPUT_DIM])\n",
    "        #         fake_data = Generator(BATCH_SIZE/len(DEVICES))\n",
    "\n",
    "        #         disc_all = Discriminator(lib.concat([real_data, fake_data],0))\n",
    "        #         disc_real = disc_all[:tf.shape(real_data)[0]]\n",
    "        #         disc_fake = disc_all[tf.shape(real_data)[0]:]\n",
    "\n",
    "        #         gen_cost = -tf.reduce_mean(Discriminator(Generator(GEN_BS_MULTIPLE*BATCH_SIZE/len(DEVICES))))\n",
    "        #         disc_cost = tf.reduce_mean(disc_fake) - tf.reduce_mean(disc_real)\n",
    "\n",
    "        #         alpha = tf.random_uniform(\n",
    "        #             shape=[BATCH_SIZE/len(DEVICES),1], \n",
    "        #             minval=0.,\n",
    "        #             maxval=1.\n",
    "        #         )\n",
    "        #         differences = fake_data - real_data\n",
    "        #         interpolates = real_data + (alpha*differences)\n",
    "        #         interpolates = tf.stop_gradient(interpolates)\n",
    "        #         gradients = tf.gradients(Discriminator(interpolates), [interpolates])[0]\n",
    "        #         slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "        #         lipschitz_penalty = 100.*tf.reduce_mean((slopes-1.)**2)\n",
    "        #         disc_cost += lipschitz_penalty\n",
    "\n",
    "        #         gen_costs.append(gen_cost)\n",
    "        #         disc_costs.append(disc_cost)\n",
    "\n",
    "        # gen_cost = tf.add_n(gen_costs) / len(DEVICES)\n",
    "        # disc_cost = tf.add_n(disc_costs) / len(DEVICES)\n",
    "\n",
    "        # if DECAY:\n",
    "        #     decay = tf.maximum(0., 1.-(tf.cast(iteration, tf.float32)/ITERS))\n",
    "        # else:\n",
    "        #     decay = 1.\n",
    "        # gen_train_op = tf.train.AdamOptimizer(learning_rate=LR*decay, beta1=MOMENTUM_G, beta2=0.9).minimize(gen_cost, var_list=lib.params_with_name('Generator'), colocate_gradients_with_ops=True)\n",
    "        # disc_train_op = tf.train.AdamOptimizer(learning_rate=LR*decay, beta1=MOMENTUM_D, beta2=0.9).minimize(disc_cost, var_list=lib.params_with_name('Discriminator.'), colocate_gradients_with_ops=True)\n",
    "\n",
    "\n",
    "    frame_i = [0]\n",
    "    fixed_noise = tf.constant(np.random.normal(size=(64, 128)).astype('float32'))\n",
    "    fixed_noise_samples = Generator(64, noise=fixed_noise)\n",
    "    def generate_image(frame):\n",
    "        samples = session.run(fixed_noise_samples)\n",
    "        samples = ((samples+1.)*(255.99/2)).astype('int32')\n",
    "        lib.save_images.save_images(samples.reshape((64, 3, 128, 128)), 'samples_{}.png'.format(frame))\n",
    "\n",
    "    if DATASET == 'imagenet':\n",
    "        train_gen = lib.imagenet.load(BATCH_SIZE)\n",
    "\n",
    "    def inf_train_gen():\n",
    "        while True:\n",
    "            for images, in train_gen():\n",
    "                yield images\n",
    "\n",
    "    session.run(tf.initialize_all_variables())\n",
    "\n",
    "    generate_image(0)\n",
    "\n",
    "    gen = inf_train_gen()\n",
    "\n",
    "    saver = tf.train.Saver(write_version=tf.train.SaverDef.V2)\n",
    "    # Uncomment this to restore params\n",
    "    # print \"WARNING RESTORING PARAMS FROM CHECKPOINT\"\n",
    "    # saver.restore(session, os.getcwd()+\"/params.ckpt\")\n",
    "\n",
    "    for _iteration in xrange(ITERS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i in xrange(CRITIC_ITERS):\n",
    "            _data = gen.next()\n",
    "            _data = _data.reshape((BATCH_SIZE,3,128,128))\n",
    "            _disc_cost, _ = session.run(\n",
    "                [disc_cost, disc_train_op], \n",
    "                feed_dict={all_real_data_conv: _data, iteration: _iteration}#, fake_data: fake_data_buffer[np.random.choice(BUFFER_LEN*BATCH_SIZE, BATCH_SIZE)]}\n",
    "            )\n",
    "\n",
    "        _ = session.run(\n",
    "            gen_train_op,\n",
    "            feed_dict={iteration: _iteration}\n",
    "        )\n",
    "\n",
    "        lib.plot.plot('cost', _disc_cost)\n",
    "        lib.plot.plot('time', time.time() - start_time)\n",
    "\n",
    "        if _iteration % 100 == 0:\n",
    "            generate_image(_iteration)\n",
    "\n",
    "        if _iteration % 1000 == 0:\n",
    "            saver.save(session, 'params.ckpt')\n",
    "\n",
    "        if _iteration % 5 == 0:\n",
    "            lib.plot.flush(print_stds=True)\n",
    "\n",
    "        lib.plot.tick()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e50e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf40aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222d801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859b77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3556b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
